\chapter{An Inlining Approach to Hardware Semantics}
\label{chap:semantics}

In this chapter, we present a formal definition of inlining.  First,
we define the inlining operation on the \Kami{} language and the
modular semantics~\cite{murali-thesis}. We then present a new semantic
approach, which is based on the inlining operation.

\paragraph{Notations}

Before defining syntax and semantics, we introduce a number of
notations to represent general data structures.
\begin{itemize}
\item Lists: we use a symbol $\vec{t}\;$ to represent a type of list
  whose elements are represented as a value $t$. \listnil{} represents
  the nil list, and $(\listcons{hd}{tl})$ represents the list with a
  head $hd$ and a tail $tl$.
\item Sets: \emptyset{} represents an empty set, $(s \cup t)$
  represents the union of sets $s$ and $t$. $(a \in S)$ denotes an
  element $a$ in set $S$.
\item Finite maps: we use a symbol $(K \finmapsymb V)$ to represent a
  finite map with a set of keys $K$ and a set of values
  $V$. \emptymap{} represents an empty map, and $\stupd{m}{k}{v}$
  represents a map update with a new key $k$ and a value
  $v$. Singletons are represented by
  $\stupd{}{k}{v}$. $(\mapfilt{m}{ks})$ represents a map where all
  elements whose keys are in the list $ks$ are removed from $m$. We
  use the notation $\in$ also for finite maps to represent that a map
  has a certain key; $(k \in m)$ means that a map $m$ has a value for
  a key $k$.
\end{itemize}

\section{Syntax}

\paragraph{Expressions}
We begin by defining syntax for expressions. Expressions consist of
constant, register read, variable, and an inductive operation among
expressions.

\begin{definition}
  \label{def-expression}
  An expression $e$ is defined inductively as follows:
  \begin{center}
    \begin{math}
      \begin{array}{rcll}
        \textrm{Expression}\quad e & ::= & c & \textrm{(constant)} \\
        & | & r & \textrm{(register read)} \\
        & | & x & \textrm{(variable)} \\
        & | & \eop{e} & \textrm{(operation)} \\
      \end{array}
    \end{math}
  \end{center}
\end{definition}

Constants denote all concrete values used in hardware design. A number
of constants with different bit-widths may exist in real hardware
design, but they are abstracted into a single type for
convenience. Let \setconst{} be the set of such constants. $c \in
\setconst{}$ will be used as a typical character representing a
constant throughout the chapter.

$r \in \setregs{}$ in expressions represents the value of a register
$r$, where \setregs{} is the set of register names. $x$ denotes a
variable bound by a continuation. We define syntax as a
continuation-passing style (CPS), hence variables are used to get the
value of a continuation argument. Lastly, \eop{e} abstracts all
operations among expressions.

\paragraph{Actions}
As explained in \refsect{sec:design-paradigm}, an action is a unit for
describing hardware behaviors, which should ensure atomicity. Actions
consist of register write, method call, let bind, conditional branch,
assert, and return.

\begin{definition}
  \label{def-action}
  An action $a$ is defined inductively as follows:
  \begin{center}
    \begin{math}
      \begin{array}{rcll}
        \textrm{Action}\quad a & ::= & \actwrite{r}{e}{a} & \textrm{(register write)} \\
        & | & \actcall{x}{f}{e}{a} & \textrm{(method call)} \\
        & | & \actlet{e}{x}{a} & \textrm{(let bind)} \\
        & | & \actifelse{e}{a}{a}{x}{a} & \textrm{(conditional branch)} \\
        & | & \actassert{e}{a} & \textrm{(assert)} \\
        & | & \actret{e} & \textrm{(return)} \\
      \end{array}
    \end{math}
  \end{center}
\end{definition}

A register write action takes a register name $r$ and an expression
$e$ to assign the evaluated value of $e$ to $r$. A method call action
takes a method name $f \in \setmeths{}$ to call, and an expression $e$
as an argument. A return value for the call is bound to a variable $x$
in a lambda continuation. \setmeths{} denotes the set of method
names. A let bind action gives a name to an expression $e$. The name
is bound to a variable $x$ in a lambda continuation. A conditional
branch action similarly has a lambda binder $x$ to capture the return
value from true and false branches. An assert action takes an
expression $e$ to be checked to progress the continuation. Lastly, a
return action takes $e$ as a return value.

Even if actions are defined in a sequential manner, they are in fact
executed concurrently. Semantically, all inference rules for actions
will use the current state to obtain values from registers, which implies
that no actions use any updated values during the execution (see
\refdef{def-semaction} for details).

Due to the concurrent execution concept, when we \emph{concatenate}
two arbitrary action sequences, we can easily imagine the behavior of
the concatenated actions simply by merging two corresponding
behaviors. The action concatenation is used for various purposes such
as inlining a method body. \refdef{def-concataction} defines a
syntactic action concatenation operator. A semantic property will be
proven in \reflem{lem-concatsymb}.

\begin{definition}
  \label{def-concataction}
  $(\concatsymb) : \textrm{Action} \to \textrm{Action} \to
  \textrm{Action}$ is an infix operator, defined inductively with
  respect to the left-hand side action:
  \begin{center}
    \begin{math}
      \begin{array}{rcl}
        \concataction{(\actwrite{r}{e}{a})}{a_c} & \triangleq & \actwrite{r}{e}{(\concataction{a}{a_c})} \\
        \concataction{(\actcall{x}{f}{e}{a})}{a_c} & \triangleq & \actcall{x}{f}{e}{(\concataction{a}{a_c})} \\
        \concataction{(\actlet{e}{x}{a})}{a_c} & \triangleq & \actlet{e}{x}{(\concataction{a}{a_c})} \\
        \concataction{(\actifelse{e}{a_t}{a_f}{x}{a})}{a_c} & \triangleq &
        \actifelse{e}{a_t}{a_f}{x}{(\concataction{a}{a_c})} \\
        \concataction{(\actassert{e}{a})}{a_c} & \triangleq & \actassert{e}{(\concataction{a}{a_c})} \\
        \concataction{(\actret{e})}{a_c} & \triangleq & \actlet{e}{x}{a_c} \\
      \end{array}
    \end{math}
  \end{center}
\end{definition}

The only nontrivial definition comes from the return statement
$(\actret{e})$. Concatenating two actions involves to pass the return
value of the left action to the right action as an argument. However,
a dynamic evaluation of an expression cannot be involved with the
static concatenation operation. The problem can be solved by using
$\textsf{let}$ syntax structure, saying that we declare a name in
which $e$ is bound, and the value is used in the body ($\lambda
x.a_c$). Considering the semantic rule for $\textsf{let}$, it is
natural to define concatenation in such a way.

\paragraph{Modules}
A module is a unit of hardware systems which has its own state (a set
of registers), rules to induce internal state changes, and methods to
communicate with other modules.

\begin{definition}
  \label{def-module}
  A module $m$ is inductively defined as follows:
  \begin{center}
    \begin{math}
      \begin{array}{rcll}
        \textrm{Module}\quad m & ::=
        & \modbasic{\regpair{r}{c}}{\rulepair{s}{a}}{\methodpair{f}{\lambda x.a}}
        & \textrm{(basic module)} \\
        & | & \modcomp{m}{m} & \textrm{(composed module)}
      \end{array}
    \end{math}
  \end{center}
\end{definition}

A module is either a \emph{basic module} or a \emph{composed module}.
In a basic module, $\listof{\regpair{r}{c}}$ represents registers
where the initial value of register $r$ is $c$.
$\listof{\rulepair{s}{a}}$ represents rules where $s$ is the name of a
rule and $a$ is the body of it. $\listof{\methodpair{f}{\lambda x.a}}$
represents methods where $f$ is the name of a method and $\lambda x.a$
is the body of it. $x$ in the lambda form serves to take an argument
of the method.

All names for registers, rules, and methods are assumed to be globally
unique in the module. A simple static checker can be implemented to
confirm that there are no name conflicts for all modules.

\section{Modular Semantics}
\label{sec-semmod}

In this section, we present a modular semantics for hardware
systems. A version of modular semantics has been defined in
\cite{murali-thesis}.  However, this section defines a slightly
different version, which is also used in the current \Kami{}
framework.  The motivation is unchanged: semantics is defined with
respect to module definitions, which includes the one for combined
modules. The semantics defined in this section will be used throughout
the thesis, including the implication proof in
\refchap{chap:implication}. Specifically, semantic definitions for
expressions and actions are completely borrowed from
\cite{murali-thesis}. Other higher semantics differ.

\paragraph{Expressions}

We start by defining semantics for expressions. \refdef{def-semexpr}
describes deterministic and denotational semantics \ssemexpr{\cdot}
for expressions.

\begin{definition}
  \label{def-semexpr}
  $\ssemexpr{\cdot} : (\sttype{}) \to \setconst$ is
  defined as follows:
  \begin{center}
    \begin{math}
      \begin{array}{rcl}
        \semexpr{c}{o} & = & c \\
        \semexpr{r}{o} & = & o(r) \\
        \semexpr{x}{o} & = & \textsf{undefined} \\
        \semexpr{\eop{e}}{o} & = & \denot{\seop{}}(\listof{\semexpr{e}{o}}) \\
      \end{array}
    \end{math}
  \end{center}
\end{definition}

Semantics for constant and register read are straightforward. The
constant itself is returned for a constant. Register read is performed
by reading its value from the \emph{old state} $o: \sttype$.

Semantics for variable is not defined, since the variable is always
substituted to the value by $\beta$-reduction at higher semantics,
before we need the semantic definition for it.  Technically, in the
\Kami{} framework, syntax is defined with PHOAS~\cite{adam-icfp}
terms, thus the variable term is abstracted into a syntax constructor
$\textsf{Var}$. In this case, we can define
$\semexpr{\textsf{Var}\ v}{o} = v$, where $v$ is a value already
substituted but still contained in the $\textsf{Var}$ constructor.

Lastly, semantics for operation is defined by using the semantic
definition for \seop{}, denoted as $\denot{\seop{}}$. Arguments are
inductively evaluated by the same semantic function.

\paragraph{Actions}

Actions are the basic unit where the communication among modules is
triggered by method calls. As defined in \refdef{def-action}, actions
contain a method call. A method call can be either internal (calling a
method in the module), or external (calling a method not in the
module).

In the modular semantics, all method calls are first treated as they
are external calls. In other words, the semantics for method calls, on
the level of action, is defined as if we know the return value of the
method for every argument. The validity of such an assumption is
checked at higher-level semantics.

\begin{definition}
  \label{def-semaction}
  The judgment \semact{o}{a}{u}{cs}{v} is defined as follows:
  \begin{center}
    \begin{math}
      \begin{array}{c}
        \inference[ActionWriteReg:]{\semexpr{e}{o} = v_r & \semact{o}{a}{u}{cs}{v}}
                  {\semact{o}{\actwrite{r}{e}{a}}{\stupd{u}{r}{v_r}}{cs}{v}} \\
        \mbox{} \\
        \inference[ActionCall:]{\semexpr{e}{o} = v_a & \semact{o}{(\lambda x.a)\ v_r}{u}{cs}{v}}
                  {\semact{o}{\actcall{x}{f}{e}{a}}{u}{\lblupd{cs}{f}{(v_a, v_r)}}{v}} \\
        \mbox{} \\
        \inference[ActionLet:]{\semexpr{e}{o} = v_l & \semact{o}{(\lambda x.a)\ v_l}{u}{cs}{v}}
                  {\semact{o}{\actlet{e}{x}{a}}{u}{cs}{v}} \\
        \mbox{} \\
        \inference[ActionIfElseT:]{\semexpr{e}{o} = \btrue{} &
          \semact{o}{a_t}{u_t}{cs_t}{v_t} &
          \semact{o}{(\lambda x.a)\ v_t}{u}{cs}{v}}
                  {\semact{o}{\actifelse{e}{a_t}{a_f}{x}{a}}{\sunion{u_t}{u}}{\sunion{cs_t}{cs}}{v}} \\
        \mbox{} \\
        \inference[ActionIfElseF:]{\semexpr{e}{o} = \bfalse{} &
          \semact{o}{a_f}{u_f}{cs_f}{v_f} &
          \semact{o}{(\lambda x.a)\ v_f}{u}{cs}{v}}
                  {\semact{o}{\actifelse{e}{a_t}{a_f}{x}{a}}{\sunion{u_f}{u}}{\sunion{cs_f}{cs}}{v}} \\
        \mbox{} \\
        \inference[ActionAssert:]{\semexpr{e}{o} = \btrue{} & \semact{o}{a}{u}{cs}{v}}
                  {\semact{o}{\actassert{e}{a}}{u}{cs}{v}} \\
        \mbox{} \\
        \inference[ActionReturn:]{\semexpr{e}{o} = v}
                  {\semact{o}{\actret{e}}{\emptymap{}}{\emptymap{}}{v}} \\
        \mbox{} \\
      \end{array}
    \end{math}
  \end{center}
\end{definition}

Semantics for actions has a form of a judgment relation
\semact{o}{a}{u}{cs}{v}, where $o : \sttype{}$ is the old state, $a$
is the target action, $u : \sttype{}$ is the \emph{updated state}
after executing $a$, $cs : \lbtype{}$ is the map from method names to
pairs of argument and return values. Lastly, $v$ is the return value
of $a$.

Semantics for actions does not check double-writes of registers or
double-calls of method calls. For instance, in the rule
ActionWriteReg, an evaluated value is simply updated to the updated
state $u$ by the register name $r$, without confirming $u$ does not
have the value for $r$. Similarly, ActionCall does not check $cs$
already has the value for $f$. As explained in
\refsect{sec:bluespec-semantics}, we separately define semantics and
well-formedness conditions. Detailed static well-formedness checks and
properties will be discussed in \refsect{sec-wf}.

An assert and a return action have straightforward semantics. Assert
requires its argument $e$ to be \btrue{}, in order to continue
execution. There is no semantics when $e$ is evaluated to \bfalse{}.
Return simply evaluates the expression $e$ to return the value.

\paragraph{Substep}
Once the semantics for actions is defined, it should be used to define
the semantics for rules or methods. As explained in
\refsect{sec:bluespec-semantics}, \Bluespec{} and \Kami{} follow the
one-rule-at-a-time semantics; only one rule is executed in a cycle,
while multiple method calls are allowed to be executed. The \Substep{}
semantics defines a single execution by a rule or a method.
Definitions are simply lifted from the semantics for actions, since a
rule or a method is defined from actions.

A notion of label is used in this semantics, in order to represent
communications with other external modules. A label has the form
\semlbl{\alpha}{ds}{cs}, where $\alpha$ is a tag to indicate whether
the label is formed by a rule or not. If the label is formed by a rule
$s \in \setrules$, it takes $(\alpharule{s})$. Otherwise, it takes
\alphameth{}. $ds$ denotes \emph{defined methods}, which are executed
in an atomic action. Similarly, $cs$ denotes \emph{called methods},
which are called in an atomic action.

The \Substep{} semantics has a form of a judgment relation
\semsstep{m}{o}{u}{\alpha}{ds}{cs}, where $m$ is the target module,
$o$ is the old state, $u$ is the updated state, and
\semlbl{\alpha}{ds}{cs} is the label formed by the execution.

\begin{definition}
  \label{def-semsstep}
  The judgment \semsstep{m}{o}{u}{\alpha}{ds}{cs} is defined as follows:
  \begin{center}
    \begin{math}
      \begin{array}{c}
        \inference[EmptyRule:]{}
                  {\semsstep{m}{o}{\emptymap}
                    {\alpharule{\epsilon}}{\emptymap}{\emptymap}} \\
        \mbox{} \\
        \inference[EmptyMeth:]{}
                  {\semsstep{m}{o}{\emptymap}
                    {\alphameth}{\emptymap}{\emptymap}} \\
        \mbox{} \\
        \inference[SingleRule:]{\rulepair{s}{a} \in \rulesofm{m} & \semact{o}{a}{u}{cs}{v}}
                  {\semsstep{m}{o}{u}{\alpharule{s}}{\emptymap}{cs}} \\
        \mbox{} \\
        \inference[SingleMeth:]{\methodpair{f}{\lambda x.a} \in \methsofm{m} &
          \semact{o}{(\lambda x.a)\ v_a}{u}{cs}{v_r}}
                  {\semsstep{m}{o}{u}{\alphameth{}}{\lblupd{}{f}{(v_a, v_r)}}{cs}} \\
        \mbox{} \\
      \end{array}
    \end{math}
  \end{center}
\end{definition}

EmptyRule and EmptyMeth describe the cases where no progress is made
in a cycle. An empty step by a rule and one by a method should be
separately defined in the \Substep{} semantics, in order to maintain
the information needed when defining the refinement
relation~\cite{murali-thesis}.

SingleRule and SingleMeth describe the case where a rule or a method
is executed in a cycle, respectively. In SingleRule, a rule $(s, a)$
should be defined in the module $m$. \rulesofm{m} is a function which
collects all rules in the module, inductively defined as follows:
\begin{definition}
  \label{def-rulesofm}
  \mbox{}
  \begin{center}
    \begin{math}
      \begin{array}{lcl}
        \rulesofm{(\_, \listof{\rulepair{s}{a}}, \_)} & = & \listof{\rulepair{s}{a}}\\
        \rulesofm{(\modcomp{m1}{m2})} & = & (\rulesofm{m1}) \cup (\rulesofm{m2})\\
      \end{array}
    \end{math}
  \end{center}
\end{definition}
Similarly, a method $(f, \lambda x.a)$ should be defined in $m$ in the
SingleMeth case. \methsofm{m} is also similarly defined as follows:
\begin{definition}
  \label{def-methsof}
  \mbox{}
  \begin{center}
    \begin{math}
      \begin{array}{lcl}
        \methsofm{(\_, \_, \listof{\methodpair{f}{\lambda x.a}})} & = & \listof{\methodpair{f}{\lambda x.a}} \\
        \methsofm{(\modcomp{m1}{m2})} & = & (\methsofm{m1}) \cup (\methsofm{m2})\\
      \end{array}
    \end{math}
  \end{center}
\end{definition}
Once a rule or a method is found, proper labels are formed by using
information from the action semantics.

\paragraph{Substeps}
The ``Substeps'' semantics collects multiple substeps which are
concurrently executed in a cycle. There are a few conditions whether
substeps can be merged or not. Conditions are about the updated states
and labels from \Substep{}. Firstly, two substeps with
$(\alpharule{\cdot})$ labels cannot be merged, since it breaks the
one-rule-at-a-time semantics. Two updated states should be disjoint
unless it breaks the double-write policy. Similarly, two defined
methods and two called methods should be disjoint not to break
double-call.

The \Substeps{} semantics has a form of a judgment relation
\semsss{m}{o}{u}{l}, where arguments mostly have the same meaning as
in \Substep{}. $l$ denotes the label formed in a cycle.

\begin{definition}
  \label{def-semsss}
  The judgment \semsss{m}{o}{u}{l} is defined as follows:
  \begin{center}
    \begin{math}
      \begin{array}{c}
        \inference[SubstepsNil:]{}
                  {\semsss{m}{o}{\emptymap}
                    {\semlbl{\alphameth}{\emptymap}{\emptymap}}} \\
        \mbox{} \\
        \inference[SubstepsCons:]{\semsss{m}{o}{u_1}{l_1} & \semsstepr{m}{o}{u_2}{l_2} & \sdisj{u_1}{u_2} & \ldisj{l_1}{l_2}}
                  {\semsss{m}{o}{\sunion{u_1}{u_2}}{\lplus{l_1}{l_2}}} \\
        \mbox{} \\
      \end{array}
    \end{math}
  \end{center}
\end{definition}

In SubstepsCons, disjointnesses of states and labels are both denoted
by the operation \sdisj{}{}, while definitions differ. For states
$u_1$ and $u_2$, \sdisj{u_1}{u_2} defines the two finite state maps
are disjoint, which can be defined naturally.

\begin{definition}
  \label{def-sdisj}
  \mbox{}
  \begin{center}
    \begin{math}
      \sdisj{u_1}{u_2} \triangleq \forall r. r \notin u_1 \vee r \notin u_2
    \end{math}
  \end{center}
\end{definition}

For labels $l_1$ and $l_2$, \ldisj{l_1}{l_2} defines the two labels
are combinable.

\begin{definition}
  \label{def-ldisj}
  \mbox{}
  \begin{center}
    \begin{math}
      \begin{array}{rcl}
        \ldisj{l_1}{l_2} & \triangleq &
        \anndisj{(\annotof{l_1})}{(\annotof{l_2})} \wedge
        \mdisj{(\defsof{l_1})}{(\defsof{l_2})} \wedge
        \mdisj{(\callsof{l_1})}{(\callsof{l_2})} \textrm{, where} \\
        \anndisj{\alpha_1}{\alpha_2} & \triangleq &
        (\alpha_1 = \alphameth) \vee (\alpha_2 = \alphameth) \\
      \end{array}
    \end{math}
  \end{center}
\end{definition}

Using the disjointness conditions, we define a label-merging operation
$(\lplus{l_1}{l_2})$, defined as follows:

\begin{definition}
  \label{def-lplus}
  \mbox{}
  \begin{center}
    \begin{math}
      \begin{array}{rcl}
        \lplus{l_1}{l_2} & \triangleq &
        \semlbl{\annplus{\annotof{l_1}}{\annotof{l_2}}}
               {\lunion{\defsof{l_1}}{\defsof{l_2}}}
               {\lunion{\callsof{l_1}}{\callsof{l_2}}} \textrm{, where} \\
        \annplus{\alpha_1}{\alpha_2} & \triangleq &
        \textsf{if}\ \alpha_1 = \alpharule{s}\ \textsf{then}\ \alpha_1\
        \textsf{else}\ \alpha_2 \\
      \end{array}
    \end{math}
  \end{center}
\end{definition}

The only nontrivial definition is $(\annplus{\alpha_1}{\alpha_2})$,
which takes rule annotations from two annotations. It returns
\alphameth{} if both of them are not a rule annotation. Note that the
two annotations cannot both be the rule annotation by the condition
$(\anndisj{\alpha_1}{\alpha_2})$, which is following the concept of
the one-rule-at-a-time semantics.

\paragraph{Step}
The \Step{} semantics describes behaviors of a module where all
internal communications are hidden. It employes the \Substep{}
semantics, and hides all internal calls of the label from the
substeps. Hiding internal calls includes to check whether the calls
are correctly defined, \ie{} if a label of substeps contains a called
method $f$ with an argument and a return value $(v_a, v_r)$, then the
label also should contain a defined method with the same name and the
value.

The \Step{} semantics has a form of a judgment relation
(\semstep{m}{o}{u}{l}), arguments have the same meaning as in
\Substeps{}.

\begin{definition}
  \label{def-semstep}
  The judgment \semstep{m}{o}{u}{l} is defined as follows:
  \begin{center}
    \begin{math}
      \begin{array}{c}
        \inference[StepIntro:]{\semsss{m}{o}{u}{l} & \wellhidden{m}{(\hide{l})}}
                  {\semstep{m}{o}{u}{l}} \\
        \mbox{} \\
      \end{array}
    \end{math}
  \end{center}
\end{definition}

(\hide{l}) computes the label where all internal (corresponding) calls
are removed.

\begin{definition}
  \label{def-hide}
  \mbox{}
  \begin{center}
    \begin{math}
      \hide{\semlbl{\alpha}{ds}{cs}} = \semlbl{\alpha}{ds - cs}{cs - ds}.
    \end{math}
  \end{center}
\end{definition}

A finite map subtraction operation $(-)$ is naturally defined; it
removes all pairs $(k, v)$ on the left-hand side map if the right-hand
side map contains $(k, v)$.

(\wellhidden{m}{l}) ensures $l$ does not contain internal calls with
respect to $m$.

\begin{definition}
  \label{def-wellhidden}
  \mbox{}
  \begin{center}
    \begin{math}
      \wellhidden{m}{\semlbl{\alpha}{ds}{cs}} \triangleq
      (\keysdisj{ds}{\callsofm{m}}) \wedge (\keysdisj{cs}{\methsofm{m}}).
    \end{math}
  \end{center}
\end{definition}

$(\callsofm{m})$ statically collects all method names which are called
in $m$.

\begin{definition}
  \label{def-callsof}
  \mbox{}
  \begin{center}
    \begin{math}
      \begin{array}{lcl}
        \callsofm{(\_, \listof{\rulepair{s}{a_r}}, \listof{\methodpair{f}{\lambda x.a_m}})}
        & = & (\bigcup_{(s_i, a_{r_i}) \in \listof{\rulepair{s}{a_r}}}\ \callsofa{a_{r_i}})\ \cup \\
        & & (\bigcup_{(f_i, \lambda x.a_{m_i}) \in \listof{\methodpair{f}{\lambda x.a_m}}}\ \callsofa{a_{m_i}}) \\
        \callsofm{(\modcomp{m_1}{m_2})} & = & \callsofm{m_1} \cup \callsofm{m_2} \\
        \callsofa{(\actwrite{r}{e}{a})} & = & \callsofa{a} \\
        \callsofa{(\actcall{x}{f}{e}{a})} & = & \{ f \} \cup \callsofa{a} \\
        \callsofa{(\actlet{e}{x}{a})} & = & \callsofa{a} \\
        \callsofa{(\actifelse{e}{a_t}{a_f}{x}{a})} & = & \callsofa{a_t} \cup \callsofa{a_f} \cup \callsof{a} \\
        \callsofa{(\actassert{e}{a})} & = & \callsofa{a} \\
        \callsofa{(\actret{e})} & = & \emptyset \\
      \end{array}
    \end{math}
  \end{center}
\end{definition}

\section{Manipulating Module Structures}

Before introducing an inlining operation and its corresponding
semantics, we present one of main properties of modular semantics,
which is also related to inlining. The property says that how modules
are composed does not affect behaviors of the modules. In other words,
two modules are semantically equivalent if they have the same set of
registers, rules, and defined methods. It is formally described as
follows:

\begin{lemma}
  \label{lem-equiv-modules}
  \mbox{}\\
  For two modules $m_1$ and $m_2$,
  \begin{center}
    \begin{math}
      \begin{array}{l}
        \regsofm{m_1} = \regsofm{m_2} \to \\
        \rulesofm{m_1} = \rulesofm{m_2} \to \\
        \methsofm{m_1} = \methsofm{m_2} \to \\
        (\semstep{m_1}{o}{u}{l}) \to (\semstep{m_2}{o}{u}{l})
      \end{array}
    \end{math}
    \end{center}
\end{lemma}

Having the same set of registers, rules, and defined methods does not
imply two modules are syntactically equal. For example, two modules
$\modcomp{(\modcomp{m_1}{m_2})}{m_3}$ and
$\modcomp{m_1}{(\modcomp{m_2}{m_3})}$ have different module structures
(thus syntactically different), but they have the same set of
registers, rules, and defined methods (from three modules $m_1$,
$m_2$, and $m_3$).

Proving \reflem{lem-equiv-modules} is straightforward, simply by
following inductive definitions of semantics. Since all inference
rules from \Substep{} to \Step{} do not look at the structure of
modules (how they are composed), the proof does not need any tricks.
Using \reflem{lem-equiv-modules}, we obtain two more intuitive
corollaries, which directly say that module structures are nothing to
do with semantics.

\begin{corollary}
  \label{lem-modules-comm}
  \mbox{}\\
  For two modules $m_1$ and $m_2$,
  \begin{center}
    \begin{math}
      \begin{array}{l}
        (\semstep{\modcomp{m_1}{m_2}}{o}{u}{l}) \to (\semstep{\modcomp{m_2}{m_1}}{o}{u}{l})
      \end{array}
    \end{math}
    \end{center}
\end{corollary}
\begin{proof}
  Straightforward by applying \reflem{lem-equiv-modules}.
\end{proof}

\begin{corollary}
  \label{lem-modules-assoc}
  \mbox{}\\
  For modules $m_1, m_2$ and $m_3$,
  \begin{center}
    \begin{math}
      \begin{array}{l}
        (\semstep{\modcomp{(\modcomp{m_1}{m_2})}{m_3}}{o}{u}{l}) \to
        (\semstep{\modcomp{m_1}{(\modcomp{m_2}{m_3})}}{o}{u}{l})
      \end{array}
    \end{math}
    \end{center}
\end{corollary}
\begin{proof}
  Straightforward by applying \reflem{lem-equiv-modules}.
\end{proof}

The independence between module structures and modular semantics
allows us to \emph{simplify} the module structure without affecting
its semantics. For instance, we can define and use a \emph{flattening
  operation} for modules. The flattening operation
$\modflatten{\cdot}$ converts a target module to one big basic module,
by breaking the module structure.

\begin{definition}
  \label{def-flattening}
  \mbox{}
  \begin{center}
    \begin{math}
      \begin{array}{lcl}
        \modflatten{m} & \triangleq & (\regsofm{m}, \rulesofm{m}, \methsofm{m})
      \end{array}
    \end{math}
  \end{center}
\end{definition}

It is obvious that $m$ and $\modflatten{m}$ satisfy the conditions for
applying \reflem{lem-equiv-modules}, thus we finally obtain the
following property:

\begin{corollary}
  \label{lem-modules-flatten}
  \mbox{}\\
  For a module $m$,
  \begin{center}
    \begin{math}
      \begin{array}{l}
        (\semstep{m}{o}{u}{l}) \to (\semstep{\modflatten{m}}{o}{u}{l})
      \end{array}
    \end{math}
    \end{center}
\end{corollary}
\begin{proof}
  Straightforward by applying \reflem{lem-equiv-modules}.
\end{proof}

Once a module is collapsed by flattening, the only concern for
efficiently dealing with modules comes from internal calls. In order
to handle such internal calls, we use inlining; given a flattened
module, the inlining operation eliminates all internal calls by
substituting their bodies to call sites. Hence, after flattening and
inlining, we obtain a \emph{raw module}, in which all internal
structures are collapsed. See \refdef{def-inlinedmm} for details how
the flattening operation is used during inlining.

\section{Well-formedness of Modules}
\label{sec-wf}

In this section, we formally define one of well-formedness conditions
of modules. Well-formedness for a programming language usually means a
set of conditions which can be \emph{statically checked} with a given
program. Since the conditions are static, they are usually defined
independent to semantic definitions, which has a dynamic aspect.  For
instance, as briefly discussed in \refsect{sec:bluespec-semantics}, it
is not allowed for a rule or a method to write the same register
twice, or to call the same method twice. These conditions can be
statically and approximately determined by examining actions.

Well-formedness conditions should be checked not only for correct
synthesis, but also for verification. Two representative
well-formedness conditions are: 1) there are no double writes or
double calls in each action, and 2) there are no call cycles in a
module. If a hardware design does not satisfy the former, then the
synthesized circuit makes structural hazards. If not satisfying the
latter, then the call cycles form a combinational cycle, whose
behavior is nonpredictable. Meanwhile, in terms of verification, a
main reason for checking well-formedness conditions is that some
semantic properties cannot be proven without them. For instance, a
correctness proof of an inlining operation requires a well-formedness
condition as a hypothesis (see \refchap{chap:implication} for
details).

Whereas, certain conditions cannot be statically checked, thus should
be defined in part of semantics. For example, when combining two
substeps, two corresponding updated states and labels are required to
be disjoint, defined in the \Substeps{} semantics. However, in some
cases, it is too challenging to statically ensure the updated states
and the labels are disjoint.

\begin{figure}[h]
  \centering{
    \begin{subfigure}[b]{0.5\textwidth}
      \bsvmodnoreg{m}{
        \bsvnone{\pgmmeth}{f}{(p)}{
          \pgmif{} p \\
          \pgmthen{} \pgmwrite{r_1}{1}
          \pgmelse{} \pgmwrite{r_2}{2}
        }\\
        \bsvnone{\pgmmeth}{g}{(q)}{
          \pgmif{} q \\
          \pgmthen{} \pgmwrite{r_1}{1}
          \pgmelse{} \pgmwrite{r_2}{2}
        }
      }
    \end{subfigure}
  }
  \caption{Two methods forming disjoint state updates}
  \label{ex-two-methods-disjoint}
\end{figure}

\reffig{ex-two-methods-disjoint} shows the case where two methods $f$
and $g$ yield disjoint state updates when $q = \neg p$, thus they can
be concurrently executed. When a condition expression $p$ is \btrue{},
then $f$ writes $r_1$ and $g$ writes $r_2$. Otherwise, if $p$ is
\bfalse{}, then $q$ is \btrue{} so $f$ writes $r_2$ and $g$ writes
$r_1$. However, it is generally challenging to provide whether two
predicates ($p$ and $q$ in the example) are disjoint or not. How can
we collect possible pairs of $(p, q)$ if the module $m$ is too
complicated to figure out callers of $f$ and $g$?

In this thesis, we define one of well-formedness conditions, which
ensures that there are no double writes or double calls for given
actions. For a given module $m$, $(\wfdouble{m})$ ensures such a
property.

\paragraph{Well-formedness for avoiding double writes and calls}

Even if detecting double writes or calls is difficult within a module,
we can provide a \emph{sound} static checker for actions. A sound
checker implies that if it says ``no double writes or calls'', then it
is correct. However, it might say ``there exist double writes or
calls'' even if such double writes or calls cannot happen.

\begin{figure}[h]
  \centering{
    \begin{subfigure}[b]{0.5\textwidth}
      \bsvmodnoreg{m}{
        \bsvnone{\pgmmeth}{f}{(p)}{
          \pgmif{} p\ \pgmthen{} \pgmwrite{r_1}{1}
          \pgmwrite{r_1}{1}
        }
      }
    \end{subfigure}
  }
  \caption{A method where double writes happen in some cases}
  \label{ex-maybe-double-writes}
\end{figure}

\reffig{ex-maybe-double-writes} shows the case where double writes
happen in some cases, but not in the other cases. If $p$ is \btrue{},
then double writes happen. Otherwise, double writes do not
happen. However, as explained with the case in
\reffig{ex-two-methods-disjoint}, analyzing predicates is difficult in
most cases. Thus, we should define a checker in a sound manner, by
assuming that $p$ can be sometimes \btrue{}.

Now we define a static checker for ensuring that there are no double
writes or calls in an action. (\wfdoubleap{a}) is inductively defined
as follows:

\begin{definition}
  \label{def-wfdoublea}
  \mbox{}
  \begin{center}
    \begin{math}
      \begin{array}{lcl}
        \wfdoublea{a} & = & \wfdoubleap{a}{\emptyset}{\emptyset} \textrm{, where} \\
        \wfdoubleap{(\actwrite{r}{e}{a})}{rs}{cs} & = & \wordif{} r \in rs \\
        & & \wordthen{} \bfalse{} \\
        & & \wordelse{} \wfdoubleap{a}{(\setadd{rs}{r})}{cs} \\
        \wfdoubleap{(\actcall{x}{f}{e}{a})}{rs}{cs} & = & \wordif{} f \in cs \\
        & & \wordthen{} \bfalse{} \\
        & & \wordelse{} \wfdoubleap{a}{rs}{(\setadd{fs}{f})} \\
        \wfdoubleap{(\actlet{e}{x}{a})}{rs}{cs} & = & \wfdoubleap{a}{rs}{cs} \\
        \wfdoubleap{(\actifelse{e}{a_t}{a_f}{x}{a})} & =
        & (\wfdoubleap{\concataction{a_t}{a}}{rs}{cs})\ \band{} \\
        & & (\wfdoubleap{\concataction{a_f}{a}}{rs}{cs}) \\
        \wfdoubleap{(\actassert{e}{a})}{rs}{cs} & = & \wfdoubleap{a}{rs}{cs} \\
        \wfdoubleap{(\actret{e})}{rs}{cs} & = & \btrue{} \\
      \end{array}
    \end{math}
  \end{center}
\end{definition}

$(\wfdoublea{a})$ is defined using $(\wfdoubleap{a}{rs}{cs})$, where
$rs$ and $cs$ are registers and method calls collected while iterating
an action, respectively. When an action is a register write or a
method call, then $(\wfdoubleap{a})$ checks if the register or the
method is already written or called, respectively. If not, it collects
the register and the method, and continues to check for next actions.
Note that the action concatenation operation $(\concatsymb)$ is used
to define the well-formedness of conditional branch actions. This is
to collect register writes and called methods for true and false
branches in parallel. See \refdef{def-concataction} for the definition
of $(\concatsymb)$.

The definition of (\wfdoublea{a}) is naturally extended to
(\wfdouble{m}), by applying it for each action in $m$.

\begin{definition}
  \label{def-wfdouble}
  \mbox{}
  \begin{center}
    \begin{math}
      \begin{array}{lcl}
        \wfdouble{(\modbasic{\regpair{r}{c}}{\rulepair{s}{a_s}}{\methodpair{f}{\lambda x.a_f}})} & =
        & (\wordforeach{} a_s.\; \wfdoublea{a_s} = \btrue)\ \band{} \\
        & & (\wordforeach{} a_f.\; \wfdouble{a_f} = \btrue) \\
        \wfdouble{(\modcomp{m_1}{m_2})} & = & (\wfdouble{m_1})\ \band{}\ (\wfdouble{m_2}) \\
      \end{array}
    \end{math}
  \end{center}
\end{definition}

\section{Inlining Semantics}
\label{sec:inlining-semantics}

In this section, we formally define an inlining operation and its
corresponding semantics. The main purpose of inlining is to handle
possible behaviors of modules easily. As explained in
\refsect{sec:related-works}, internal calls are the main hurdle
analyzing module behaviors. However, in consequence of inlining, a
module will no longer have internal calls, which implies that the
inlined module is easy to analyze.

\subsection{Inlining Operation}

\paragraph{Inlining a method}
There are several ways to implement an inlining function. One way is
to define it like a breadth-first search; during the iteration of a
target action, called methods are inlined for each method call. This
inlining process is applied repeatedly until there are no internal
method calls.

We define an inlining function in a somewhat different way for proof
efficiency. First, we pick a function which will be inlined throughout
a target module. Then for every action in the target module, we search
for all method calls to the target method, and inline all of
them. This process is applied for every defined method in the
module. The reason we chose this way is that inlining a single method
is closely related to semantic label manipulation. See
\refchap{chap:implication} for the detailed reason why this inlining
is easier to prove properties.

For a target action $a$ and an inlining method $dm$, we define a
method-inlining operator for an action, denoted as $(\inlinedmsymb)$.

\begin{definition}
  \label{def-inlinedm}
  $(\inlinedmsymb) : \textrm{Action} \to \textrm{Method} \to
  \textrm{Action}$ is an infix operator, defined inductively with
  respect to the left-hand side action:
  \begin{center}
    \begin{math}
      \begin{array}{rcl}
        \inlinedm{(\actwrite{r}{e}{a})}{dm} & \triangleq &
        \actwrite{r}{e}{(\inlinedm{a}{dm})} \\
        \inlinedm{(\actcall{x}{f}{e}{a})}{(f_i, \lambda x.a_f)} & \triangleq &
        \pgmif{} f = f_i \\
        & & \pgmthen{} \concataction{(\actlet{e}{y}{(\lambda x.a_f)\ y})}{(\inlinedm{a}{(f_i, \lambda x.a_f)})} \\
        & & \pgmelse{} \actcall{x}{f}{e}{(\inlinedm{a}{(f_i, \lambda x.a_f)})} \\
        \inlinedm{(\actlet{e}{x}{a})}{dm} & \triangleq &
        \actlet{e}{x}{(\inlinedm{a}{dm})} \\
        \inlinedm{(\actifelse{e}{a_t}{a_f}{x}{a})}{dm} & \triangleq &
        \actifelse{e}{(\inlinedm{a_t}{dm})}{(\inlinedm{a_f}{dm})}{x}{(\inlinedm{a}{dm})} \\
        \inlinedm{(\actassert{e}{a})}{dm} & \triangleq &
        \actassert{e}{(\inlinedm{a}{dm})} \\
        \inlinedm{(\actret{e})}{dm} & \triangleq & \actret{e} \\
      \end{array}
    \end{math}
  \end{center}
\end{definition}

A method-inlining operator for a module is naturally defined by
extending the operator for an action. For a target module $m$ and an
inlining \emph{method name} $f$, we define a method-inlining operator
for a module, denoted as $(\inlinedmmsymb)$. Note that module is
flattened (as defined in \refdef{def-flattening}) during the inlining
process.

\begin{definition}
  \label{def-inlinedmm}
  $(\inlinedmmsymb) : \textrm{Module} \to \setmeths{} \to
  \textrm{Module}$ is an infix operator, defined as follows:
  \begin{center}
    \begin{math}
      \begin{array}{rcl}
        \inlinedmm{m}{f} & \triangleq & \pgmlet{} dm = (\methsofm{m})[f]\ \pgmin{} \\
        & & \pgmif{} \isrec{dm}\ \pgmthen{} \fail{} \\
        & & \pgmelse{} \\
        & & \pgmlet{} \listof{\regpair{r}{c}} = \regsofm{m}\ \pgmin{} \\
        & & \pgmlet{} \listof{\rulepair{s}{a_s}} = \rulesofm{m}\ \pgmin{} \\
        & & \pgmlet{} \listof{\methodpair{f}{\lambda x.a_f}} = \methsofm{m}\ \pgmin{} \\
        & & \modbasic{\regpair{r}{c}}
                  {\rulepair{s}{(\inlinedm{a}{dm})}}
                  {\methodpair{f}{\lambda x.(\inlinedm{a}{dm})}} \\
      \end{array}
    \end{math}
  \end{center}
\end{definition}

\paragraph{Inlining all defined methods}

Using the method-inlining operator $(\inlinedmmsymb)$, now it is
straightforward to define an inlining function for a module. We simply
apply $(\inlinedmmsymb)$ for all defined methods in the module.

However, inlining gets complicated when there is \emph{a call cycle}
in the module. \reffig{ex-inlining-callcycle} shows the case where
inlining for such a module is problematic. A module $m$ has two
methods $f$ and $g$. It has a call cycle since $f$ calls $g$ and $g$
calls $f$. When inlining $g$ first, $f$ becomes a
\emph{self-recursive} call (a right figure). In this case, inlining
for $f$ cannot progress, since inlining itself will cause register
double-writes by $r_1$ and $r_2$. In order to avoid such cases, the
method-inlining operator checks whether the method which will be
inlined has a self-recursive method call or not. As described in
\refdef{def-inlinedmm}, (\isrec{dm}) ensures that $dm$ is not
self-recursive.

\begin{figure}[t]
  \begin{subfigure}[b]{0.5\textwidth}
    \bsvmodnoreg{m}{
      \bsvnone{\pgmmeth}{f}{}{
        \pgmwrite{r_1}{1}
        \pgmcalln{g}{}
      }\\
      \bsvnone{\pgmmeth}{g}{}{
        \pgmwrite{r_2}{2}
        \pgmcalln{f}{}
      }
    }
    \subcaption{Before inlining $g$}
  \end{subfigure}
  \begin{subfigure}[b]{0.5\textwidth}
    \bsvmodnoreg{m}{
      \bsvnone{\pgmmeth}{f}{}{
        \pgmwrite{r_1}{1}
        \pgmwrite{r_2}{2}
        \pgmcalln{f}{}
      }
    }
    \subcaption{After inlining $g$}
  \end{subfigure}
  \caption{A call cycle during inlining}
  \label{ex-inlining-callcycle}
\end{figure}

Now we naturally extend the method-inlining operator to a
methods-inlining operator $(\inlinedmssymb)$.

\begin{definition}
  \label{def-inlinedms}
  $(\inlinedmmsymb) : \textrm{Module} \to \textrm{list}\ \setmeths{}
  \to \textrm{Module}$ is an infix operator, defined as follows:
  \begin{center}
    \begin{math}
      \begin{array}{rcl}
        \inlinedms{m}{\listnil} & \triangleq & m \\
        \inlinedms{m}{\listcons{f}{fs}} & \triangleq & \inlinedms{(\inlinedmm{m}{f})}{fs} \\
      \end{array}
    \end{math}
  \end{center}
\end{definition}

Using the methods-inlining operator $(\inlinedmssymb)$, we finally define the
inlining operator $\inline{\cdot}$ for a target module $m$.

\begin{definition}
  \label{def-inline}
  $\inline{\cdot} : \textrm{Module} \to \textrm{Module}$ is defined as
  follows:
  \begin{center}
    \begin{math}
      \inline{m} \triangleq \inlinedms{m}{(\namesof{(\methsofm{m})})}
    \end{math}
  \end{center}
\end{definition}

Why are method names used for inlining, instead of actual method
bodies? The reason is that when we do inlining once for a particular
method, then all related method bodies are changed. In other words,
when a method-inlining is done, we should take a new method which will
be inlined next, by taking it from the \emph{inlined module}, not from
the original one.

\paragraph{Hiding internal methods}

The last step of inlining is to hide internal methods so that they
cannot be called from external modules. It is to ensure an original
module and the inlined one have the same behaviors. According to the
modular semantics, all interal methods cannot be called by external
methods. In terms of inlining, when all internal calls are inlined,
then the module should not have interfaces for these inlined methods.

How do we know which defined methods should be hidden? The way to hide
such methods is simple; we simply filter defined methods by checking
whether the target method is internally called by some rules or
methods.

\begin{definition}
  \label{def-inlineF}
  $\inlineF{\cdot} : \textrm{Module} \to \textrm{Module}$ is defined
  as follows:
  \begin{center}
    \begin{math}
      \inlineF{m} \triangleq
      (\regsofm{\inline{m}},
      \rulesofm{\inline{m}},
      \mapfilt{(\methsofm{\inline{m}})}{(\callsofm{m})}),
    \end{math}
  \end{center}
\end{definition}
where the map filtering operator $(\mapfilt{m}{l})$ filters out
elements of $m$ where the key is not in $l$.

\subsection{Inlining Semantics}

\begin{figure}[t]
  \begin{subfigure}[b]{0.5\textwidth}
    \bsvmodnoreg{m}{
      \bsvnone{\pgmrule}{s}{}{
        \pgmwrite{r_1}{1}
        \pgmcalln{f}{}
      }\\
      \bsvnone{\pgmmeth}{f}{}{
        \pgmwrite{r_2}{2}
        \pgmcalln{g}{}
      }\\
      \bsvnone{\pgmmeth}{g}{}{
        \pgmwrite{r_3}{3}
      }
    }
    \subcaption{Before applying the inlining operator $\inlineF{\cdot}$}
  \end{subfigure}
  \begin{subfigure}[b]{0.5\textwidth}
    \bsvmodnoreg{\inlineF{m}}{
      \bsvnone{\pgmrule}{r}{}{
        \pgmwrite{r_1}{1}
        \pgmwrite{r_2}{2}
        \pgmwrite{r_3}{3}
      }
    }
    \subcaption{After applying the inlining}
  \end{subfigure}
  \caption{Inlining efficiency with respect to the \Step{} semantics}
  \label{ex-inlining-efficiency}
\end{figure}

Using the complete inlining operator, we finally define the inlining
semantics. It borrows the \Step{} semantics from the modular
semantics. The \StepInl{} semantics have a form of a judgment relation
(\semstepin{m}{o}{u}{l}), arguments have the same meaning as in
\Step{}.

\begin{definition}
  \label{def-semstepin}
  The judgment \semstepin{m}{o}{u}{l} is defined as follows:
  \begin{center}
    \begin{math}
      \begin{array}{c}
        \inference[StepInlIntro:]{\semstep{\inlineF{m}}{o}{u}{l}}
                  {\semstepin{m}{o}{u}{l}} \\
        \mbox{} \\
      \end{array}
    \end{math}
  \end{center}
\end{definition}

\Step{} semantics can be efficiently handled by using inlining. In
other words, dealing with \Step{} with inlined modules is easier than
ordinary modules. \reffig{ex-inlining-efficiency} describes two
modules, where the left module is an original module (which is not
inlined), while the right one is inlined. We can clearly see that the
inlined module is simpler than the original one. More formally, the
inlined module is easily handled, since 1) it has fewer defined
methods, and 2) the module has no internal calls.

