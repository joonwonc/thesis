\chapter{Introduction: What Makes Hardware Verification Complex}

%% Design and verification of cache-coherence protocols have been long-lasting challenges for almost a half century.
%% Cite Coq when introduced.

\chapter{Background}

Before introducing our proposed method to design and prove cache-coherence protocols more structurally, in this chapter we provide some background to understand conventional cache-coherence protocol designs and typical correctness challenges.
We first introduce a very simple cache-coherence protocol to explain the purpose of the protocol, basic design, and a number of nontrivial corner cases that require careful handling.
After that, we explore some design space of cache-coherence protocols for better understanding of the case-study protocols we will provide in \autoref{sec-case-study}.

\section{Cache-Coherence Protocols In a Nutshell}
\label{sec-nutshell}

In this section, we provide a simple yet motivating example to explain the typical challenges.
For simplicity, throughout the section, we will consider a protocol protecting only \emph{a single memory location}.
We will see it is still nontrivial to design and verify a correct protocol.

The overall goal of cache coherence is, as the name suggests, to preserve coherence among multiple candidate values in a memory subsystem.
In other words, if the system is coherent, then it should behave like an atomic memory.
This behavior inclusion is formally defined as \emph{refinement}, which will be introduced in \autoref{sec-semantics}.
The correctness of a cache-coherence protocol is sometimes shown by proving representative invariants, not talking about the relation to the desired spec.
The single-writer/multiple-reader (SWMR) invariant and the data-value invariant~\cite{ccbook:2020} are classic choices; in proving the refinement of a protocol, these invariants (or similar ones) must be proven.

\begin{figure}[t]
  \centering
  \begin{tikzpicture}
    \pic at (0, 0) {skeleton-pcce12={$P(S, v, S_{\tuple{1, 2}})$}{$C_1(S, v)$}{$C_2(S, v)$}};
    \pic at (0, 0) {skeleton-midx-e1};
    \pic at (0, 0) {skeleton-midx-e2};
    \pic at (0, 0) {skeleton-midx-pc1};
    \pic at (0, 0) {skeleton-midx-pc2};
    \node at (3.0, -1) {$\sqsubseteq$};
    \pic at (4.5, -0.7) {spec};
  \end{tikzpicture}
  \caption{A simple MSI directory protocol and its spec}
  \label{fig-motive-1}
\end{figure}

\autoref{fig-motive-1} shows caches and communication channels for a simple directory-based MSI protocol (LHS of $\sqsubseteq$).
Since we deal with only a single memory location, the specification (RHS of $\sqsubseteq$) is a single-value ($v$) container with atomic read and write.
There are three caches ($P$, $C_1$, and $C_2$) in the implementation, and each of them has its own status (M, S, or I) and data ($v$).
The status of a cache represents a permission on its local replica.
In this MSI protocol, an object can read/write the data with the M (``modified'') status, only read with S (``shared''), and cannot read/write with I (``invalid'').
The parent $P$ additionally has a data structure called a \emph{directory} to track the statuses of the children.
For example, a directory might be $S_{\tuple{1, 2}}$, meaning that both $C_1$ and $C_2$ have S status, in some logical snapshot of state.

Objects communicate through ordered channels, shown as $(\rightarrowtail)$ in the figure, where each of it has a unique index (shown as a natural number in the figure).
$C_1$ and $C_2$ have channels to receive and respond to external requests (from processor cores).
There are three types of channels between a parent and a child: a single channel for parent-to-child messages and two channels for child-to-parent requests and responses, respectively.
It is natural to wonder why two separate channels are required from a child to a parent; we will see the reason very soon.
Note that channels are depicted in a logical way; the actual hardware implementation may use different hardware components (\eg{} finite-capacity FIFOs or buses) that can simulate ordered channels.

\begin{figure}[t]
  \centering
  \begin{tikzpicture}
    \pic at (0, 0) {skeleton-pcce12={$P(S, v, S_{\tuple{1, 2}})$}{$C_1(S, v)$}{$C_2(S, v)$}};
    % C_1 external
    \pic at (0, 0) {skeleton-midx-e1};
    \node[label={[label distance=-6pt,myred]left:{\rdrecmsgsm{a}{rqWr}}},color=myred] at (-1.8, -2.35) {$\bullet$};
    % C_2 external
    \pic at (0, 0) {skeleton-midx-e2};
    \node[label={[label distance=-6pt,myblue]left:{\blrecmsgsm{e}{rqWr}}},color=myblue] at (1.6, -2.35) {$\bullet$};
    % Between P and C_1
    \pic at (0, 0) {skeleton-midx-pc1};
    \node[label={[label distance=-6pt,myred]left:{\rdrecmsgsm{b}{rqM}}},color=myred] at (-1.1, -0.8) {$\bullet$};
    % Between P and C_2
    \pic at (0, 0) {skeleton-midx-pc2};
    \node[label={[label distance=-9pt,myred]below right:{\rdrecmsgsm{d}{rsI}}},color=myred] at (0.9, -0.8) {$\bullet$};
    \node[label={[label distance=-9pt,myred]above right:{\rdrecmsgsm{c}{rqI}}},color=myred] at (1.1, -0.8) {$\bullet$};
    \node[label={[label distance=-9pt,myblue]below left:{\blrecmsgsm{f}{rqM}}},color=myblue] at (0.7, -0.8) {$\bullet$};

    % Curves
    \draw [->,color=myred] (-2.95, -2.05) to[out=90,in=-110] node {\rdcircf{1}} (-2.35, -1.05);
    \draw [->,color=myred] (-2.25, -0.5) to[out=70,in=110,distance=2cm] node {\rdcircf{3}} (1.7, -0.2);
    \draw [->,color=myred] (2.2, -0.7) to[out=-40,in=-40,distance=1.2cm] node {\rdcircf{4}} (2.0, -1.1);
    \draw [->,color=myblue] (0.7, -2.0) to[out=90,in=-45] node {\blcircf{2}} (0.3, -1.4);

  \end{tikzpicture}
  \caption{Rule-execution cases in the simple MSI protocol}
  \label{fig-motive-2}
\end{figure}

\autoref{fig-motive-2} depicts some example state-transition cases depending on statuses of the caches.
All the caches run concurrently, repeatedly executing \emph{rules} that define local state transitions.
A rule may take some messages from input channels, perform a state transition, and put messages in output channels.
A rule may also have a precondition, blocking use of that rule when the precondition does not hold.
$\rdcircf{1}$ shows the case where a child $C_1$ takes an external request (\rdrecmsgsm{a}{rqWr}) to write data, but it does not have M status and thus further requests to the parent (\rdrecmsgsm{b}{rqM}) to get the permission.
At this moment, in many cache-coherence protocol designs, $C_1$ changes its status to a \emph{transient state} SM to record its current status (S) and the next expected status (M).
This transient state also functions as a \emph{lock} not to allow any further external requests for the value.

Due to the concurrent execution of the caches, we might have another rule executed at the same time.
$\blcircf{2}$ is executed concurrently with $\rdcircf{1}$, where $C_2$ also takes an external request (\blrecmsgsm{e}{rqWr}) with the same purpose, thus requests \blrecmsgsm{f}{rqM} to the parent as well.
Since $\rdcircf{1}$ and $\blcircf{2}$ happened at the same time, now the parent $P$ needs to decide which request to deal with.
Suppose that it decided to handle \rdrecmsgsm{b}{rqM} first.

$\rdcircf{3}$ presents the next execution by $P$, taking the input message \rdrecmsgsm{b}{rqM} and making an \emph{invalidation} request (\rdrecmsgsm{c}{rqI}) to the other child $C_2$ to change its status to I.
This invalidation request is required, since when a child has M the others should not be able to read/write the data.
The parent, at this moment, changes its directory status to a transient state (named $S^D$ in some textbooks) to disallow any other requests from the children.
For instance, the parent should not handle \blrecmsgsm{f}{rqM}, since otherwise it will handle two ``\msgsf{rqM}''s simultaneously, which might lead to an incoherent state -- two M statuses in the caches.

Lastly, $\rdcircf{4}$ shows the case that $C_2$ handles the invalidation request (\rdrecmsgsm{c}{rqI}).
A number of corner cases should be handled carefully in this case:
\begin{itemize}[leftmargin=*]
\item Since $C_2$ requested \blrecmsgsm{f}{rqM}, it has a transient state SM when \rdrecmsgsm{c}{rqI} arrives. It should still be able to handle this invalidation request even in the transient state (while not allowing any external requests). In this case $C_2$ accepts \rdrecmsgsm{c}{rqI} and changes its transient state to IM. We see that transient states should be fine-grained enough to distinguish which requests to handle.
\item Due to the existence of \blrecmsgsm{f}{rqM}, if we had a single channel from a child to a parent, a deadlock would occur. $P$ cannot take \blrecmsgsm{f}{rqM} since it has been locked (in a transient state) after making an invalidation request. It cannot take \rdrecmsgsm{d}{rsI} as well since the response is not the first one of the ordered channel. This case shows the necessity of having multiple channels between a child and a parent.
\end{itemize}

A so-called three-channel system has been widely used and regarded as a good choice to make the design correct and live~\cite{Murali:2015,thesis:Murali:2016}.
While there are other possible correct topology and network settings, the cases shown in \autoref{fig-motive-2} at least demonstrate that it is nontrivial to construct one of them.

\begin{figure}[t]
  \centering
  \begin{tikzpicture}
    \pic at (0, 0) {skeleton-pcce12={$P(S, v, S_{\tuple{1, 2}})$}{$C_1(S, v)$}{$C_2(S, v)$}};
    % C_1 external
    \pic at (0, 0) {skeleton-midx-e1};
    \node[label={[label distance=-6pt,myred]right:{\rdrecmsgsm{i}{rsWr}}},color=myred] at (-1.6, -2.35) {$\bullet$};
    % C_2 external
    \pic at (0, 0) {skeleton-midx-e2};
    % Between P and C_1
    \pic at (0, 0) {skeleton-midx-pc1};
    \node[label={[label distance=-12pt,myred]below right:{\rdrecmsgsm{g}{rsM}}},color=myred] at (-0.9, -1.0) {$\bullet$};
    \node[color=myblue] at (-0.5, -0.6) {$\bullet$};
    \node at (-1.5, -0.3) {\blrecmsgsm{h}{rqI}};
    \draw [densely dashed,color=myblue,line width=0.3pt] (-0.5, -0.6) to[out=170,in=-10] (-1.1, -0.3);

    \node[color=myblue] at (-0.8, -0.7) {$\bullet$};
    \node at (-2.5, -0.5) {\blrecmsgsm{j}{rsI}};
    \draw [densely dashed,color=myblue,line width=0.3pt] (-0.8, -0.7) to[out=190,in=-10] (-2.05, -0.5);

    % Between P and C_2
    \pic at (0, 0) {skeleton-midx-pc2};
    \node[label={[label distance=-9pt,myred]above right:{\rdrecmsgsm{d}{rsI}}},color=myred] at (0.9, -0.8) {$\bullet$};
    \node[color=myblue] at (0.7, -0.8) {$\bullet$};
    \node at (2.0, 0.2) {\blrecmsgsm{f}{rqM}};
    \draw [densely dashed,color=myblue,line width=0.3pt] (0.7, -0.8) to[out=70,in=210] (1.5, 0.1);

    % Curves
    \draw [->,color=myred] (1.05, -0.5) to[out=180,in=60] node {\rdcircf{5}} (-0.6, -1.1);
    \draw [->,color=myred] (-0.6, -1.5) to[out=-90,in=80] node {\rdcircf{7}} (-0.8, -2.2);
    \draw [->,color=myblue] (2.0, 0.4) to[out=130,in=80,distance=1.5cm] node {\blcircf{6}} (-1.5, -0.1);
    \draw [->,color=myblue] (-1.5, -0.5) to[out=245,in=-115,distance=0.9cm] node {\blcircf{8}} (-2.5, -0.8);
    \draw [->,color=myblue] (-2.5, -0.3) to[out=90,in=-100] (-2.0, 0.7);
    \node[color=myblue] at (-2.0, 1.1) {$\vdots$};

  \end{tikzpicture}
  \caption{Rule-execution cases, continued}
  \label{fig-motive-3}
\end{figure}

\autoref{fig-motive-3} presents some additional rule-execution cases right after $\rdcircf{4}$ in \autoref{fig-motive-2}.
After $\rdcircf{4}$ responds with \rdrecmsgsm{d}{rsI}, now $P$ can take it to respond back to $C_1$.
$\rdcircf{5}$ presents this step, taking \rdrecmsgsm{d}{rsI} and responding back to $C_1$ with \rdrecmsgsm{g}{rsM}.
At this moment $P$ changes its status to $P(I, ?, M_{(1)})$ (from the transient state $S^D$) to record that it no longer has the coherent value and just granted $C_1$ the M status.
Since the transient state also functions like a lock, this status change can be also regarded as a lock release, so that $P$ can handle some other requests.

$\blcircf{6}$ is the next transition step by $P$ to accept a new request.
\blrecmsgsm{f}{rqM} has been waiting for the transient state of $P$ to be released, and $\blcircf{6}$ finally takes it and sends an invalidation request to $C_1$.

Looking at the message channel $5$, the one for parent-to-child messages (from $P$ to $C_1$), there are two messages, \rdrecmsgsm{g}{rsM} and \blrecmsgsm{h}{rqI}, residing in the channel.
A single parent-to-child channel affects the correctness of the protocol in this case.
If we had two separated downward channels, one for requests and the other for responses, $C_1$ could handle \blrecmsgsm{h}{rqI} first, changes its status to I, handles \rdrecmsgsm{g}{rsM} later, and changes its status to M again.
Since it sent the invalidation response to the parent, eventually $C_2$ will also get the M status, which leads to an incoherent state.
Therefore, it is crucial to have a single parent-to-child channel so that \rdrecmsgsm{g}{rsM} \emph{blocks} \blrecmsgsm{h}{rqI} to be handled first.
After $C_1$ takes \rdrecmsgsm{g}{rsM} and responds back to the processor core with \rdrecmsgsm{i}{rsWr}, presented as $\rdcircf{7}$, it can subsequently take the invalidation request \blrecmsgsm{h}{rqI} and responds with \blrecmsgsm{j}{rsI}, as shown in $\blcircf{8}$.

As examined in \autoref{fig-motive-2} and \autoref{fig-motive-3}, in a cache-coherence protocol, transient states and network channels play a crucial role in making \emph{interleavings} correct.
Regarding the sequence of rule executions (in red) $[\rdcircf{1}; \rdcircf{3}; \rdcircf{4}]$ as an execution flow in \autoref{fig-motive-2} -- we will call it a \emph{transaction} in later sections -- to handle the original external request \rdrecmsgsm{a}{rqWr}, we see that no further executions could happen after $\blcircf{2}$, which is for the other request \blrecmsgsm{e}{rqWr}.
As explained above case-by-case, proper transient states and network channels block \blrecmsgsm{f}{rqM} from further processing.
Similarly, in \autoref{fig-motive-3}, the execution flow $[\rdcircf{5}; \rdcircf{3}]$ was not spuriously affected by $\blcircf{6}$ or $\blcircf{8}$, thanks to the correct channel setting.

If proper locking (by transient states) and topology are crucial for designing a correct protocol, can we craft a domain-specific language where only conformant protocols are expressible?
That is exactly what \hemiola{} provides: it provides \emph{rule templates}, explained in \autoref{sec-rule-templates}, that employ proven-safe topologies and network structures and automatically set associated locks, so designers can design protocols without worrying about corner cases due to interleavings.

\section{Design Space of Cache-Coherence Protocols}
\label{sec-design-space}

In \autoref{sec-nutshell}, we examined a very specific protocol design.
There are different ways to design a cache-coherence protocol, and each design decision affects performance and correctness of the protocol.
In this section, we explore major design space of a cache-coherence protocol.

\subsubsection{Snooping vs. Directory}

A typical classification of a cache-coherence protocol is whether the protocol employs a designated data structure to keep track of the statuses of child caches.
There are two representative classes: \emph{snooping} and \emph{directory} protocols.

A snooping protocol does not use any data structure to monitor the statuses of child caches.
Instead, when the parent communicates with child caches, it \emph{broadcasts} a message to the children.
Each child cache decides whether to respond to the message from the parent or just to ignore it, depending on its status.
For example, suppose the scenario, already mentioned in \autoref{sec-nutshell}, that the parent wants to an invalidation request to downgrade the status of the child who has the M status to I.
Since the parent cache does not have any information which child currently has the M status, it has no choice but to broadcast the invalidation-request message to all of the children.
The child cache with the M status will respond to the parent after invalidating its status, while the other caches will just ignore the request.
In actual hardware implementations, snooping is usually implemented with an ordered wire bus shared by the parent and the children.

A directory protocol, as its name says, uses the directory structure to record which child has which status.
The example presented in \autoref{sec-nutshell} is a directory protocol; we see that the parent $P$ additionally has a directory data structure.
Considering the same invalidation scenario, because the parent knows which child has the M status exactly, it can make the invalidation request just to that child.

A snooping protocol is known to be easier to implement than a directory protocol, since the ordered bus enforces less interleavings among transactions.
That being said, the snooping protocol is also known not to be scalable, since the cost of broadcasting increases significantly when more child caches are involved.
A directory protocol, on the other hand, is known to be scalable and especially matches well hierarchy layers, but the design and verification are relatively more difficult than the snooping protocol.

This dissertation only deals with directory protocols due to their inherent difficulties.
We will build a framework that can ease the burden of designing and verifying directory protocols, and demonstrate the practicality of the framework with various hierarchical directory protocols as case studies.

\subsubsection{Write-update vs. Write-invalidate}

A cache-coherence protocol can be also classified by the patterns of memory writes.
Amony various memory-write patterns, we classify the protocol by when each legal write to a cache is propagated to the other caches.
Then we have two classes: \emph{write-update} and \emph{write-invalidate} protocols.

In a write-update protocol, if a cache wants to write to a line, it requests to update the lines in the other caches first and updates its line after the updates by the others.
This protocol is beneficial when a cache writes to a line and the other caches wants to read it right after the write.

In a write-invalidate protocol, if a cache wants to write to a line, it first requests to invalidate the lines in the other caches so that they cannot read or write the line.
Once all the other caches are invalidated, it can write a new value.
The write-invalidate policy is used more generally in practical cache-coherence protocols, since the write-update policy requires more bandwidth (to carry the up-to-date written value) and is not efficient when some other caches actually do not need to read the up-to-date value anymore.

\subsubsection{Write-through vs. Write-back}

Another criterion about memory writes is when a write to a cache is applied to the main memory; it provides two classes as well: \emph{write-through} and \emph{write-back} protocols.

In a write-through protocol, when a cache writes to a line (already with enough permission), it further requests a write to the main memory as well.
This protocol is easier to design, since the up-to-date value can be always found in the main memory.

On the other hand, in a write-back protocol, a cache does not requests to the main memory to send the value when writing to a line.
The write-back policy is harder to implement than the write-through protocol, since the protocol should provide a way to find the up-to-date -- possibly dirty -- value among all the caches, \eg{} by managing directories that point the cache that has the value.
That being said, almost all practical cache-coherence protocols use the write-back policy to avoid unnecessary writeback to the main memory.

All the case-study protocols in this dissertation, which will be introduced in \autoref{sec-case-study}, follow the write-invalidate and write-back policies.

\subsubsection{Inclusive vs. Noninclusive vs. Exclusive}

The protocol we introduced in \autoref{sec-nutshell} is a flat (\ie{} nonhierarchical) protocol in that child caches ($C_1$ and $C_2$) communicates directly with the parent $P$ as the main memory with a directory.
In other words, there are no intermediate caches between the lowest-level caches (called the L1 caches) and the main memory.
There is an essential tradeoff between caches and the memory: caches have much faster latency than the memory but lower hit rate.
In order to mitigate the hit rate of a cache, hierarchical cache-coherence protocols have been developed and used.
In a hierarchical protocol, some of the L1 caches are clustered to have an L2 cache as the parent, and so on.
A higher-level cache usually has a lower latency than lower-level caches but has a better hit rate due to its increased size.

Hierarchical cache-coherence protocols can be classified by so-called the \emph{cache-inclusion policy}.
Especially when designing a protocol with directories, it is practically easier to design caches to follow the requirement that every line in the value cache has its corresponding directory entry in the directory cache, and vice versa.
It is indeed easier to design with such a policy, since it allows to combine an information cache (\ie{} the one containing line statuses, etc.) and a directory cache into a single cache, which is more space-efficient by not having to store tags in each cache.
This policy, in other words, means that whenever a line is in a child cache there is a corresponding line in the parent cache as well.
We therefore call it \emph{inclusive}, meaning that the parent cache includes the lines in child caches.

Inclusive caches have a benefit that certain requests from the parent can be responded immediately just by searching the directory status.
For example, when a cache gets an invalidation request from the parent and the line entry does not exist in the directory, it does not need to forward the request to the children for the complete invalidation, since by the inclusion policy absense of the directory status already implies that the line does not exists in any of the child caches.
That said, inclusive caches have a drawback that some value entries are wasted; for example, when a directory status is M, meaning that a child has the possibly dirty value, the parent does not need to hold any stale value inside the value cache.

A \emph{noninclusive} cache -- also called a noninclusive nonexclusive (NINE) cache -- does not require such inclusion.
Since it does not require the inclusion, it has less chance to waste value lines.
That said, the biggest drawback comes when a directory-status entry does not exist in the directory cache; the absense of the directory status does not imply that child caches do not have the line.
The same issue occurs in a snooping protocol as well; \eg{} a cache should always snoop all the child caches in order to handle an invalidation request from the parent.

In order to resolve the addressed issues, a number of practical cache-coherence protocols are known to manage noninclusive (value) caches and inclusive directories, called NCID~\cite{Zhao:2010}.
Intel Skylake-X processors are known to use noninclusive caches~\cite{intel-non-inclusive,Yan:2019}.
By having noninclusive value caches we have less chance to waste value lines, and by having inclusive directories we do not always need to visit child caches for invalidation.

On the contrary to the inclusive cache, an \emph{exclusive} cache intends to maximize the utility between child caches and the parent one, by requiring that the lines of each child and the parent are disjoint to each other.
AMD Opteron servers are known to use exclusive caches~\cite{Irazoqui:2016}.
A similar optimization to NCID is possible in exclusive caches, by managing directories as inclusive while the value caches are exclusive.
