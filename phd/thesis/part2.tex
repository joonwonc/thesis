\part{A Framework with the Serializability Guarantee}

\chapter{The \hemiola{} Domain-Specific Language}
\label{sec-hemiola-dsl}

As explained in \autoref{sec-sz-def}, on top of serializability, it is much easier to design and prove invariants.
That being said, it will still be a large burden if a user has to prove serializability per-protocol.
In this chapter, we would like to provide \emph{abstract conditions} to prove serializability, in order not to prove it directly for each protocol.
Furthermore, we design a domain-specific language (DSL) that every protocol defined on top of this language automatically satisfies the conditions to guarantee serializability.
The conditions have already been mentioned with the motivating example in \autoref{sec-nutshell} -- network topology and locking mechanisms, extracted from transient states of practical cache-coherence protocols.

\section{Topology and Network Requirements}
\label{sec-topo-net-reqs}

In order to employ the serializability guarantee in \hemiola{}, the objects in a given system should form a tree topology.
Most cache-coherent memory subsystems follow this topology, where leaf nodes correspond to L1 caches, and the root corresponds to the main memory.
A child and its parent in the tree communicate using the three channels shown in \autoref{sec-nutshell}: an upward-request channel, an upward-response channel, and a single downward channel.
Note that the use of the three channels does not mean the actual hardware implementation should use just the three channels; it can use any channel implementation that refines the three channels regarded as a specification.
For example, we may want to have an additional queue that accepts all the requests from child caches (from the corresponding upward-request channels), so the parent can have a single entry point to handle child requests.
We will indeed see in \autoref{sec-comp-syn} how logical channels in \hemiola{} are implemented in a register-transfer level.

\hemiola{} as a Coq library generates the topology and network channels automatically from instances of a simple inductive type.
For example, the following tree definition will generate topology and channels for four L1 caches, two L2 caches, the last-level cache (LLC), and the main memory:
\begin{lstlisting}[numbers=none, frame=none]
  Definition t: tree := Node [Node [Node [Leaf; Leaf]; Node [Leaf; Leaf]]].
\end{lstlisting}

\section{Locking Mechanism}
\label{sec-locking-mechanism}

We saw in \autoref{sec-nutshell} why fine-grained transient states are required to ensure safe interleavings in cache-coherence protocols.
Revisiting the corner case described in \autoref{fig-motive-2}, a child should be able to handle an invalidation request from the parent even if it is in a transient state (SM), and after the response it changes its transient state to IM.
By looking at these transient states carefully, we have discovered that another necessary condition, other than the tree-topology condition, is the locking perspective from the transient states.

\hemiola{} supports a general locking mechanism reflecting this discovery;
instead of looking at the type of a message (\eg{} invalidation), the framework provides \emph{more-general} locking, just by looking at whether the message is from the parent or one of its children.
This relaxed locking mechanism is then not coupled with any specific cache-coherence protocols but is still sufficient to prove serializability.

\tikzset{
  uprightedge/.pic = {
    \draw [>->] (0.2, 0.25) -- (0.8, 1.05);
  },
}
\begin{figure}[h]
  \centering
  \begin{tikzpicture}
    \node at (0, 0) {$C$};
    \pic at (0, 0) {uprightedge};
    \node[label={[label distance=-4pt]right:{\small {\sf rq1}}}] at (0.45, 0.6) {$\bullet$};
    \node at (1.0, 1.3) {$P_1$};
    \pic at (1.0, 1.3) {uprightedge};
    \node[label={[label distance=-4pt]left:{\small {\sf rq2}}}] at (1.55, 2.0) {$\bullet$};
    \node at (2.0, 2.6) {$P_2$};

    \draw [>=stealth,double,->] (2.3, 2.35) -- (2.9, 1.55);
    \node[label={[label distance=-4pt]right:{\small $\overline{\textsf{rqs}}$}}] at (2.55, 2.0) {$\bullet$};

    \node[draw,align=left] at (4.0, 0.2) {$P_1$ sets an uplock\\ when sending {\small $\textsf{rq2}$} to $P_2$};
    \node[draw,align=left] at (6.4, 2.0) {$P_2$ sets a downlock\\ when sending {\small $\overline{\textsf{rqs}}$} to children};
  \end{tikzpicture}
  \caption{The uplock and downlock in \hemiola{}}
  \label{fig-locking}
\end{figure}

In particular, \hemiola{} provides two kinds of locks: \emph{uplocks and downlocks}.
We say an object is uplocked (or downlocked) when it holds an uplock (or downlock), respectively.
\autoref{fig-locking} depicts the locking mechanism in \hemiola{}.
An uplock is set when an object makes an upward request to its parent ($P_1$ in the figure); it is released when the object gets a corresponding response from the parent.
On the contrary, a downlock is set when an object makes a downward request(s) to some of its children ($P_2$ in the figure).

\begin{figure}[h]
  \centering
  \renewcommand{\arraystretch}{1.2}
  \newcommand{\lockyes}{\cmark}
  \newcommand{\lockno}{\xmark}
  \begin{tabular}{ccc}
    \hline
    & Uplocked & Downlocked\\
    \hline
    Acquiring an uplock & \lockno & \lockyes\\
    Releasing an uplock & \lockyes & \lockno\\
    Acquiring a downlock & \lockyes & \lockno\\
    Releasing a downlock & \lockyes & \lockyes\\
    \hline
  \end{tabular}
  \caption{Locking conditions in \hemiola{}}
  \label{fig-locking-conditions}
\end{figure}

\autoref{fig-locking-conditions} shows the conditions to acquire or release the locks.
An uplock can be set if the object is not yet uplocked; it can be set even when the object is downlocked.
This locking mechanism means that an object can make a request to the parent even when it has made requests to the children.
It is still safe, since the lock release will not be allowed when downlocked, \ie{} the uplock release should always wait for the downlock to be released.
On the other hand, a downlock \emph{can be set and released even when uplocked}.
This relaxation is very important to make the locking mechanism both safe and live.
If a downlock could not be released when uplocked, we would have a deadlock case, where the both locks wait for each other.

Now every cache object defined in \hemiola{} \emph{does not need to set transient states} to consider all combinations among stable statuses;
instead, the framework helps maintain the cache status and claim proper locks.
For example, instead of setting a transient state SM, it is now desirable to maintain its status S and to set an uplock to record it just made the upward request.
(The framework provides even more, actually, by guiding users to employ the \emph{rule templates}, introduced in the next section, that automatically set proper locks.)

Each object defined in \hemiola{} has a semantic \emph{lock state}, a finite map from a lock type (uplock or downlock) to lock information: the original request message, the original requestor index, and requestee indices from which we expect to get responses.
In the common terminology of cache-coherence protocols, each lock corresponds to a miss status holding register (MSHR).
An MSHR is set when a cache miss happens and the miss triggers further requests to obtain a proper status and up-to-date data.
As with \hemiola{} lock holders, MSHRs play a crucial role both in deciding whether to handle certain requests and in storing information needed to handle them properly.

It is worth emphasizing that an uplock and a downlock are assigned for each line.
In other words, the locking conditions presented in \autoref{fig-locking-conditions} do not apply to the locks for different cache lines.
This separation is safe, since in a cache-coherence protocol the transactions for different cache lines never interfere with each others.
It is not practical, however, to have an uplock and a downlock for each line in the actual hardware implementation.
We need to restrict the number of locks (MSHRs) to make the implementation synthesizable.
A detailed discussion about this restriction will be provided in \autoref{sec-comp-syn}.

\section{Rule Templates}
\label{sec-rule-templates}

\newcommand{\rtname}[1]{{\small\sf\bf #1}}

\newcommand{\uled}{\ensuremath{\textsf{UL}}}
\newcommand{\dled}{\ensuremath{\textsf{DL}}}
\newcommand{\ulfree}{\ensuremath{\textsf{UL}_{\times}}}
\newcommand{\dlfree}{\ensuremath{\textsf{DL}_{\times}}}

\newcommand{\setul}{\ensuremath{\textsf{UL}\Uparrow}}
\newcommand{\setdl}{\ensuremath{\textsf{DL}\Uparrow}}
\newcommand{\relul}{\ensuremath{\textsf{UL}\Downarrow}}
\newcommand{\reldl}{\ensuremath{\textsf{DL}\Downarrow}}
\newcommand{\stsilent}{\ensuremath{\textsf{SLT}}}

\newcommand{\ppo}[3]{\ensuremath{\{#1\}#2\lbrack#3\rbrack}}
\newcommand*{\bfrac}[2]{\genfrac{}{}{0pt}{}{#1}{#2}}

On top of the topology/network requirements and the locking mechanism, \hemiola{} provides rule templates to ensure that objects communicate within the topology and locks are properly set.
In this section, we will explore what kinds of rule templates \hemiola{} provides and discuss their uses.
Each rule template will be introduced with the form $\ppo{P}{O}{Q}$ and arrows with $\circ$ and $\bullet$, which means that the rule template is for an object $O$, requires input messages ($\circ$) and a precondition $P$, performs a state transition $Q$, and generates output messages ($\bullet$).
$\uled$, $\dled$, $\ulfree$, and $\dlfree$ in a precondition indicate that the object is uplocked, downlocked, uplock-free, and downlock-free, respectively.
$\setul$, $\setdl$, $\relul$, and $\reldl$ in a state transition indicate setting an uplock, setting a downlock, releasing an uplock, and releasing a downlock, respectively.
$\stsilent{}$ annotates that the rule template forbids any state modification beside locking.

\paragraph{Rule templates for immediate responses}

\begin{center}
  \begin{tabular}{p{0.18\textwidth}p{0.77\textwidth}}
    \begin{adjustbox}{valign=t}
      \begin{tikzpicture}
        \draw [dotted] (-0.1, 0.5) -- (-0.1, 0.8);
        \draw [dotted] (0.1, 0.5) -- (0.1, 0.8);
        \node at (0, 0.2) {$\ppo{\bfrac{\ulfree{}}{\dlfree{}}}{O}{\cdot}$};
        \draw [<-<] (-0.1, -0.2) -- (-0.1, -0.8);
        \draw [>->] (0.1, -0.2) -- (0.1, -0.8);
        \node[label={[label distance=-6pt]left:{\small {\sf rq}}}] at (-0.1, -0.5) {$\circ$};
        \node[label={[label distance=-6pt]right:{\small {\sf rs}}}] at (0.1, -0.5) {$\bullet$};
        \node at (0, -0.5) {$(\qquad\quad)$};
        \node at (0, -1.3) {{\bf (a) immd}};
      \end{tikzpicture}
    \end{adjustbox}&
    An immediate-down ({\bf immd}) rule responds immediately to an upward request, requiring the both locks free.
    This rule possibly does not take (and generate) any input (and output) messages, respectively.
    (The input/output messages are parenthesized in the form.)
    In other words, using this rule, an object can make a local state transition without any input/output messages, but in this case the both locks should be free.
    This rule also shows that a transaction may start without any input messages as a trigger, which still matches the definition of externally atomic histories in \autoref{fig-atomic-trs}.
  \end{tabular}
\end{center}

\begin{center}
  \begin{tabular}{p{0.18\textwidth}p{0.77\textwidth}}
    \begin{adjustbox}{valign=t}
      \begin{tikzpicture}
        \draw [<-<] (-0.1, 0.1) -- (-0.1, 0.8);
        \draw [>->] (0.1, 0.1) -- (0.1, 0.8);
        \node at (0, -0.2) {$\ppo{\dlfree{}}{O}{\cdot}$};
        \draw [dotted] (-0.1, -0.5) -- (-0.1, -0.8);
        \draw [dotted] (0.1, -0.5) -- (0.1, -0.8);
        \node[label={[label distance=-6pt]left:{\small {\sf rq}}}] at (-0.1, 0.45) {$\circ$};
        \node[label={[label distance=-6pt]right:{\small {\sf rs}}}] at (0.1, 0.45) {$\bullet$};
        \node at (0, -1.3) {{\bf (b) immu}};
      \end{tikzpicture}
    \end{adjustbox}&
    An immediate-up ({\bf immu}) rule responds immediately to a downward request, and it only requires the downlock free.
    In other words, even when uplocked, an object can make a state transition by taking a downward request and generating an upward response immediately.\\
  \end{tabular}
\end{center}

\paragraph{Rule templates to communicate with the parent}

\begin{center}
  \begin{tabular}{p{0.18\textwidth}p{0.77\textwidth}}
    \begin{adjustbox}{valign=t}
      \begin{tikzpicture}
        \draw [>->] (0, 0.3) -- (0, 0.8);
        \node at (0, 0) {$\ppo{\ulfree{}}{O}{\bfrac{\setul{}}{\stsilent{}}}$};
        \draw [<-<] (0, -0.3) -- (0, -0.8);
        \node[label={[label distance=-6pt]left:{\small {\sf rq}}}] at (0, -0.55) {$\circ$};
        \node[label={[label distance=-6pt]left:{\small {\sf rq}}}] at (0, 0.55) {$\bullet$};
        \node at (-0.1, -0.55) {$(\qquad)$};
        \node at (0, -1.3) {{\bf (c) rquu}};
      \end{tikzpicture}
    \end{adjustbox}&
    A request-up-up ({\bf rquu}) rule (possibly) takes an upward request from a child and make another request to the parent.
    It requires the uplock to be free but does not care whether the object is downlocked or not.
    A state transition is not allowed when setting any lock (either an uplock or a downlock).
  \end{tabular}
\end{center}

\begin{center}
  \begin{tabular}{p{0.18\textwidth}p{0.77\textwidth}}
    \begin{adjustbox}{valign=t}
      \begin{tikzpicture}
        \draw [<-<] (0, 0.3) -- (0, 0.8);
        \node at (0, 0) {$\ppo{\bfrac{\uled{}}{\dlfree{}}}{O}{\relul{}}$};
        \draw [>->] (0, -0.3) -- (0, -0.8);
        \node[label={[label distance=-6pt]left:{\small {\sf rs}}}] at (0, 0.55) {$\circ$};
        \node[label={[label distance=-6pt]left:{\small {\sf rs}}}] at (0, -0.55) {$\bullet$};
        \node at (-0.1, -0.55) {$(\qquad)$};
        \node at (0, -1.3) {{\bf (d) rsdd}};
      \end{tikzpicture}
    \end{adjustbox}&
    A response-down-down ({\bf rsdd}) rule is a dual of the {\bf rquu} rule, which takes a downward response and (possibly) responds to the original child requestor.
    This rule releases the corresponding uplock.
    Note that in order to handle a response from the parent, the object should be downlock-free.
    This precondition is indeed required to ensure correctness (serializability), as explained in \autoref{sec-locking-mechanism}.
  \end{tabular}
\end{center}

\paragraph{Rule templates to communicate with children}

\begin{center}
  \begin{tabular}{p{0.18\textwidth}p{0.77\textwidth}}
    \begin{adjustbox}{valign=t}
      \begin{tikzpicture}
        \draw [dotted] (-0.2, 0.5) -- (-0.2, 0.8);
        \draw [dotted] (0.2, 0.5) -- (0.2, 0.8);
        \node at (0, 0.2) {$\ppo{\dlfree{}}{O}{\bfrac{\setdl{}}{\stsilent{}}}$};
        \draw [<-<] (-0.2, -0.1) -- (-0.2, -0.8);
        \draw [>=stealth,double,->] (0.2, -0.1) -- (0.2, -0.8);
        \node[label={[label distance=-6pt]left:{\small {\sf rq}}}] at (-0.2, -0.45) {$\circ$};
        \node[label={[label distance=-6pt]right:{\small {\sf {\bf rqs}}}}] at (0.2, -0.45) {$\bullet$};
        \node at (-0.35, -0.45) {$(\enspace\quad)$};
        \node at (0, -1.3) {{\bf (d) rqud}};
      \end{tikzpicture}
    \end{adjustbox}&
    A request-up-down ({\bf rqud}) rule (possibly) takes an upward request and makes downward requests to some of the children except the child requestor.
    A downlock is set in this case, and thus no state transition is allowed.
    This rule does not have a precondition that the object should be uplock-free, \ie{} the object can handle a request from the parent even when uplocked.
    This relaxation is still safe in terms of correctness (serializability) and necessary to avoid a deadlock.
  \end{tabular}
\end{center}

\begin{center}
  \begin{tabular}{p{0.18\textwidth}p{0.77\textwidth}}
    \begin{adjustbox}{valign=t}
      \begin{tikzpicture}
        \draw [dotted] (-0.2, 0.5) -- (-0.2, 0.8);
        \draw [dotted] (0.2, 0.5) -- (0.2, 0.8);
        \node at (0, 0.2) {$\ppo{\dled{}}{O}{\reldl{}}$};
        \draw [>->] (-0.2, -0.1) -- (-0.2, -0.8);
        \draw [>=stealth,double,<-] (0.2, -0.1) -- (0.2, -0.8);
        \node[label={[label distance=-6pt]left:{\small {\sf rs}}}] at (-0.2, -0.45) {$\bullet$};
        \node[label={[label distance=-6pt]right:{\small {\sf {\bf rss}}}}] at (0.2, -0.45) {$\circ$};
        \node at (-0.35, -0.45) {$(\enspace\quad)$};
        \node at (0, -1.3) {{\bf (e) rsud}};
      \end{tikzpicture}
    \end{adjustbox}&
    A response-up-down ({\bf rsud}) rule is a dual of the {\bf rqud} rule, which takes upward responses and (possibly) responds back to the original child requestor.
    The rule releases the corresponding downlock.
    As explained in \autoref{sec-locking-mechanism}, it does not require any conditions on the uplock.
  \end{tabular}
\end{center}

\begin{center}
  \begin{tabular}{p{0.18\textwidth}p{0.77\textwidth}}
    \begin{adjustbox}{valign=t}
      \begin{tikzpicture}
        \draw [<-<] (0, 0.3) -- (0, 0.8);
        \node at (0, 0) {$\ppo{\dlfree{}}{O}{\bfrac{\setdl{}}{\stsilent{}}}$};
        \draw [>=stealth,double,->] (0, -0.3) -- (0, -0.8);
        \node[label={[label distance=-6pt]left:{\small {\sf rq}}}] at (0, 0.55) {$\circ$};
        \node[label={[label distance=-6pt]left:{\small {\sf {\bf rqs}}}}] at (0, -0.55) {$\bullet$};
      \end{tikzpicture}
    \end{adjustbox}&
    A request-down-down ({\bf rqdd}) rule takes a downward request (from the parent) and makes downward requests to some of the children.
    Similar to {\bf rqud}, a downlock is set, and no state transition is allowed.
    This rule also does not require the object to be uplock-free, which is to avoid a deadlock.
  \end{tabular}
\end{center}

\begin{center}
  \begin{tabular}{p{0.18\textwidth}p{0.77\textwidth}}
    \begin{adjustbox}{valign=t}
      \begin{tikzpicture}
        \draw [>->] (0, 0.3) -- (0, 0.8);
        \node at (0, 0) {$\ppo{\dled{}}{O}{\reldl{}}$};
        \draw [>=stealth,double,<-] (0, -0.3) -- (0, -0.8);
        \node[label={[label distance=-6pt]left:{\small {\sf rs}}}] at (0, 0.55) {$\bullet$};
        \node[label={[label distance=-6pt]left:{\small {\sf {\bf rss}}}}] at (0, -0.55) {$\circ$};
      \end{tikzpicture}
    \end{adjustbox}&
    A response-up-up ({\bf rsuu}) rule is a dual of the {\bf rqdd} rule, which takes upward responses and responds back to the parent.
    Similar to {\bf rsud}, this rule also releases the corresponding downlock.
  \end{tabular}
\end{center}

\paragraph{A rule template for the whole-tree traversal}

\begin{center}
  \begin{tabular}{p{0.18\textwidth}p{0.77\textwidth}}
    \begin{adjustbox}{valign=t}
      \begin{tikzpicture}
        \draw [<-<] (0, 0.3) -- (0, 0.8);
        \node at (0, 0) {$\ppo{\bfrac{\uled{}}{\dlfree{}}}{O}{\bfrac{\relul{}}{\setdl{}}}$};
        \draw [>=stealth,double,->] (0, -0.3) -- (0, -0.8);
        \node[label={[label distance=-6pt]left:{\small {\sf rs}}}] at (0, 0.55) {$\circ$};
        \node[label={[label distance=-6pt]left:{\small {\sf {\bf rqs}}}}] at (0, -0.55) {$\bullet$};
      \end{tikzpicture}
    \end{adjustbox}&
    A response-down-request-down rule ({\bf rsrq}) takes a downward response (from the parent) and makes new downward requests to some of the children.
    It makes a \emph{transfer} from an uplock to a new downlock by releasing the uplock and setting a downlock, where the child-requestor information is moved from the uplock.
    This rule forces the order of a traversal, saying that the traversal for the outer objects must be done before traversing the inner objects.
    The forced order is important to avoid a deadlock.
    For example, if the object makes requests to its parent and children at the same time and sets both an uplock and a downlock, a deadlock may occur.
  \end{tabular}
\end{center}

\paragraph{Remarks}

The rule templates are carefully designed to perform any practical transactions \emph{safely} with serializable behavior.
Consider an extreme case in a cache-coherence protocol.
When an L1 cache wants to obtain a write permission, all the other caches should be invalidated (changing each cache status to Invalid).
In order to perform such a transaction, it must be able to traverse all the other caches.
This transaction kind is one of the longest-running in cache-coherence protocols, and the rule templates are designed with proper locking ($\uled$ and $\dled$) and a state-change condition ($\stsilent$), not to create any incoherence while such a long transaction is interleaved with other transactions.

\chapter{Serializability Guarantee by \hemiola{}}

In this chapter, we provide the proof of serializability in \hemiola{}.
As introduced in \autoref{sec-hemiola-dsl}, the proof largely requires the two conditions: the tree topology with the three channel kinds (introduced in \autoref{sec-topo-net-reqs}) and the locking mechanism (introduced in \autoref{sec-locking-mechanism}).
Since the \hemiola{} DSL with the rule templates faithfully follows such conditions, we can also say that just using the DSL ensures serializability.
While conventional approaches to verifying cache-coherence protocols deal with transient states directly and induce noninterference lemmas per-state, \hemiola{} provides the serializability guarantee as \emph{the most general form of noninterference, obtained from conditions that are not coupled to any specific cache-coherence protocol}, \eg{} the DSL does not mention anything about cache-coherence protocols.

In proving serializability we use a well-established technique called commuting reductions~\cite{reduction}.
This reduction technique has been used before to prove correctness of concurrent software~\cite{Chajed:2018} and distributed systems~\cite{Hawblitzel:2015,Hawblitzel:2017}, but to our knowledge no past work has tried to discover serializability conditions for cache-coherence protocols and proved them using reductions.

\section{The Intuition: Merging Atomic-History Fragments}
\label{sec-sz-pf-intuition}

\newcommand{\commstep}[2]{\ensuremath{#1 \leftrightarrowtriangle #2}}
\newcommand{\commhst}[2]{\ensuremath{#1 \leftrightarrowtriangle #2}}

We first present our intuition of how commuting reductions are used in the serializability proof; in order for it, we need to formalize commuting reductions first.
The most basic commuting reduction happens between two adjacent state-transition steps:
\begin{definition}[Commutativity of steps]
  Two adjacent state-transition steps commute, denoted as \commstep{(\semstep{S}{s_0}{l_0}{s_1})}{(\semstep{S}{s_1}{l_1}{s_2})}, if the state transitions with the opposite order reach the same state:
  \begin{displaymath}
    \commstep{(\semstep{S}{s_0}{l_0}{s_1})}{(\semstep{S}{s_1}{l_1}{s_2})} \triangleq \exists s_1'.\; \semstep{S}{s_0}{l_1}{s_1'} \wedge \semstep{S}{s_1'}{l_0}{s_2}.
  \end{displaymath}
\end{definition}
We will write just $\commstep{l_0}{l_1}$ when the system $S$ and the transition-step adjacency (\ie{} existence of the intermediate state $s_1$) are clear from context.

We can naturally lift the definition to one for histories to argue whether two histories commute or not:
\begin{definition}[Commutativity of histories]
  Two adjacent histories commute, denoted as \commstep{(\semsteps{S}{s_0}{h_0}{s_1})}{(\semstep{S}{s_1}{h_1}{s_2})}, if the state transitions with the opposite order reach the same state:
  \begin{displaymath}
    \commhst{(\semsteps{S}{s_0}{h_0}{s_1})}{(\semsteps{S}{s_1}{h_1}{s_2})} \triangleq \exists s_1'.\; \semsteps{S}{s_0}{h_1}{s_1'} \wedge \semsteps{S}{s_1'}{h_0}{s_2}.
  \end{displaymath}
\end{definition}
We overload the same notation for history commutativity.
We will also use the shorter version $\commhst{h_0}{h_1}$ with clear context.

Our high-level intuition for the serializability proof is that for a given interleaved history we can perform a finite number of reductions to get a sequential history that reaches the same state.
More specifically, we will try to \emph{merge} any two separated atomic-history fragments by performing reductions.

\begin{figure}[t]
  \centering
  \begin{tabular}{cc}
    \begin{tikzpicture}
      \pic at (0, 0) {skeleton-pcce1={$P$}{$C_1$}{$C_2$}};
      % C_1 external
      \pic at (0, 0) {skeleton-midx-e1};
      \node[label={[label distance=-6pt,myred]left:{\small {\sf rqWr}}},color=myred] at (-1.8, -2.3) {$\bullet$};
      \node[label={[label distance=-6pt,myred]right:{\small {\sf rsWr}}},color=myred] at (-1.6, -2.3) {$\bullet$};
      % Between P and C_1
      \pic at (0, 0) {skeleton-midx-pc1};
      \node[label={[label distance=-6pt,myred]left:{\small {\sf rqM}}},color=myred] at (-1, -0.7) {$\bullet$};
      \node[label={[label distance=-9pt,myred]below right:{\small {\sf rsM}}},color=myred] at (-0.6, -0.7) {$\bullet$};
      % Between P and C_2
      \pic at (0, 0) {skeleton-midx-pc2};
      \node[label={[label distance=-9pt,myred]below left:{\small {\sf rsI}}},color=myred] at (0.8, -0.7) {$\bullet$};
      \node[label={[label distance=-6pt,myred]right:{\small {\sf rqI}}},color=myred] at (1, -0.7) {$\bullet$};

      % Curves
      \draw [->,color=myred] (-2.3, -2.0) to[out=90,in=-90] node[left] {\rdcircflsm{1}{rquu}} (-1.8, -1.0);
      \draw [->,color=myred] (-1.7, -0.4) to[out=70,in=110,distance=1.8cm] node[left=18pt] {\rdcircflsm{3}{rqud}} (1.4, -0.4);
      \draw [->,color=myred] (1.6, -0.9) to[out=-50,in=-50,distance=1.9cm] node[below] {\rdcircflsm{4}{immu}} (0.5, -1.3);
      \draw [->,color=myred] (0.4, -0.8) to[out=135,in=45,distance=0.6cm] (-0.3, -0.7);
      \draw [densely dashed,color=myred,line width=0.3pt] (0, -0.35) to[out=90,in=-170] (1.6, 0.35);
      \node at (2.0, 0.3) {\rdcircflsm{5}{rsud}};
      \draw [->,color=myred] (-0.6, -1.1) to[out=225,in=90] node[below right] {\rdcircflsm{7}{rsdd}} (-1.1, -2.0);
    \end{tikzpicture} &
    \begin{tikzpicture}
      \pic at (0, 0) {skeleton-pcce2={$P$}{$C_1$}{$C_2$}};
      % C_2 external
      \pic at (0, 0) {skeleton-midx-e2};
      \node[label={[label distance=-6pt,myblue]right:{\small {\sf rsWr}}},color=myblue] at (1.8, -2.3) {$\bullet$};
      \node[label={[label distance=-6pt,myblue]left:{\small {\sf rqWr}}},color=myblue] at (1.6, -2.3) {$\bullet$};
      % Between P and C_1
      \pic at (0, 0) {skeleton-midx-pc1};
      \node[label={[label distance=-9pt,myblue]above left:{\small {\sf rsI}}},color=myblue] at (-0.8, -0.7) {$\bullet$};
      \node[label={[label distance=-10pt,myblue]below right:{\small {\sf rqI}}},color=myblue] at (-0.6, -0.7) {$\bullet$};
      % Between P and C_2
      \pic at (0, 0) {skeleton-midx-pc2};
      \node[label={[label distance=-6pt,myblue]right:{\small {\sf rsM}}},color=myblue] at (1, -0.7) {$\bullet$};
      \node[label={[label distance=-6pt,myblue]below:{\small {\sf rqM}}},color=myblue] at (0.6, -0.7) {$\bullet$};

      % Curves
      \draw [->,color=myblue] (1.1, -2.0) to[out=90,in=-45] node[below left=-3pt] {\blcircflsm{2}{rquu}} (0.6, -1.3);
      \draw [->,color=myblue] (0.4, -0.8) to[out=135,in=45,distance=0.5cm] (-0.3, -0.7);
      \draw [densely dashed,color=myblue,line width=0.3pt] (0, -0.35) to[out=90,in=-170] (1.6, 0.35);
      \node at (2.0, 0.3) {\blcircflsm{6}{rqud}};
      \draw [->,color=myblue] (-0.6, -1.2) to[out=-135,in=-135,distance=2.1cm] node[below] {\blcircflsm{8}{immu}} (-1.4, -0.7);
      \draw [->,color=myblue] (-1.1, -0.2) to[out=60,in=120,distance=1.7cm] node[left=18pt] {\blcircflsm{9}{rsud}} (1.4, -0.5);
      \draw [->,color=myblue] (1.7, -0.95) to[out=-90,in=90] node[above right=-2pt] {\blcircflsm{10}{rsdd}} (2.3, -2.0);
    \end{tikzpicture}
  \end{tabular}
  \caption{The two interleaving transactions}
  \label{fig-ex-sz-trs}
\end{figure}

We elaborate this intuition more by using a concrete example.
\autoref{fig-ex-sz-trs} shows two interleaving transactions in {\color{myred} red} and {\color{myblue} blue}, started from $C_1$ and $C_2$, respectively, both pursuing the M status from the simple MSI protocol presented in \autoref{sec-nutshell}.
We use an arrow ({\color{myred} $\to$}) and a label (\rdcircfl{1}{\textrm{rquu}}) to denote a state transition by a rule defined with a certain rule template, \eg{} \rdcircfl{1}{\textrm{rquu}} is a rule in $C_1$ using the ``rquu'' rule template, taking an input message \idmsf{1}{rqWr} and outputting \idmsf{3}{rqM}.

We introduce each state transition here to understand the interleaving better:
\begin{itemize}
\item \rdcircfl{1}{rquu} and\blcircfl{2}{rquu}: forward \msgsfsm{rqM} to $P$ since $C_1$ (or $C_2$) does not have the M status.
\item \rdcircfl{3}{rqud} and\blcircfl{6}{rqud}: $P$ makes an invalidation request to the other child ($C_2$ and $C_1$, respectively).
\item \rdcircfl{4}{immu} and\blcircfl{8}{immu}: $C_2$ (or $C_1$) changes its status to I and responds with \msgsfsm{rsI} immediately.
\item \rdcircfl{5}{rsud} and\blcircfl{9}{rsud}: the invalidation has finished so $P$ responds with \msgsfsm{rsM} to the original requestor.
\item \rdcircfl{7}{rsdd} and\blcircfl{10}{rsdd}: $C_1$ (or $C_2$) takes the response and upgrades its status to M.
\end{itemize}

\begin{figure}[t]
  \centering
  \renewcommand{\arraystretch}{1.2}
  \setlength\tabcolsep{2.5pt}
  \begin{tabular}{c}
    \multicolumn{1}{l}{
      \begin{tikzpicture}
        \node at (0, 0) {};
        \node[anchor=west] at (2.3, 0.4) {{\small\it State transition timeline}};
        \draw [>=stealth,->,line width=1pt] (2.3, 0) to (9, 0);
    \end{tikzpicture}}\\
    \begin{tabular}{c|ccccccccccc}
      \hline
      $C_1$ & & \rdcircf{1} & & & & & & \rdcircf{7} & \blcircf{8} & & \\
      \hline
      $P$ & & & & \rdcircf{3} & & \rdcircf{5} & \blcircf{6} & & & \blcircf{9} & \\
      \hline
      $C_2$ & & & \blcircf{2} & & \rdcircf{4} & & & & & & \blcircf{10} \\
      \hline
    \end{tabular}\\
    \vspace{-10pt}\\
    $\downarrow$ (merge $[\rdcircf{3}; \rdcircf{4}; \rdcircf{5}]$ and $[\rdcircf{7}]$ by commuting $\blcircf{6}$ and $\rdcircf{7}$)\\
    \vspace{-10pt}\\
    \begin{tabular}{c|ccccccccccc}
      \hline
      $C_1$ & & \rdcircf{1} & & & & & \rdcircf{7} & & \blcircf{8} & & \\
      \hline
      $P$ & & & & \rdcircf{3} & & \rdcircf{5} & & \blcircf{6} & & \blcircf{9} & \\
      \hline
      $C_2$ & & & \blcircf{2} & & \rdcircf{4} & & & & & & \blcircf{10} \\
      \hline
    \end{tabular}\\
    \vspace{-10pt}\\
    $\downarrow$ (merge $[\rdcircf{1}]$ and $[\rdcircf{3}; \rdcircf{4}; \rdcircf{5}; \rdcircf{7}]$ by commuting $[\blcircf{2}]$ and $[\rdcircf{3}; \rdcircf{4}; \rdcircf{5}; \rdcircf{7}]$)\\
    \vspace{-10pt}\\
    \begin{tabular}{c|ccccccccccc}
      \hline
      $C_1$ & & \rdcircf{1} & & & & \rdcircf{7} & & & \blcircf{8} & & \\
      \hline
      $P$ & & & \rdcircf{3} & & \rdcircf{5} & & & \blcircf{6} & & \blcircf{9} & \\
      \hline
      $C_2$ & & & & \rdcircf{4} & & & \blcircf{2} & & & & \blcircf{10} \\
      \hline
    \end{tabular}
  \end{tabular}
  \caption{Serialization of an interleaved history by reductions}
  \label{fig-ex-sz-state-trs}
\end{figure}

\autoref{fig-ex-sz-state-trs} shows the original legal interleaved history (top) and how reductions apply to it and make it sequential (bottom).
In order to merge $[\rdcircf{3}; \rdcircf{4}; \rdcircf{5}]$ and $[\rdcircf{7}]$, either the commutation $\commhst{[\rdcircf{3}; \rdcircf{4}; \rdcircf{5}]}{[\blcircf{6}]}$ or $\commhst{[\blcircf{6}]}{[\rdcircf{7}]}$ should hold.
We will say that $[\blcircf{6}]$ is \emph{pushed} to the left (or right) when it commutes with $[\rdcircf{3}; \rdcircf{4}; \rdcircf{5}]$ (or $[\rdcircf{7}]$), respectively.

Two state transitions trivially commute if 1) the object state transitions happen in different objects and 2) input/output channels used for the transitions are all orthogonal to each other.
(We will formalize this intuition as a lemma in the actual serializability proof, shown in \autoref{sec-sz-proof}.)
If either of the conditions does not hold, we may need to analyze more.

\begin{figure}[t]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \begin{tikzpicture}
      % Alignment
      \node at (-3.6, 0) {};
      \node [anchor=north west,text width=2.5cm,inner sep=4pt,draw] at (-3.3, 0.4) {{\small \blmsgsm{rqI} and \rdmsgsm{rsM} are different, due to their message types.}};

      \node at (0, 0.5) {$P$};
      \node at (0, 0.15) {\tiny $5$};
      \draw [line width=0.2mm, >->] (0, 0) -- (0, -1.2);
      \node[label={[label distance=-4pt,myblue]right:{\small {\sf rqI}}},color=myblue] at (0, -0.4) {$\bullet$};
      \node[label={[label distance=-4pt,myred]right:{\small {\sf rsM}}},color=myred] at (0, -0.8) {$\bullet$};
      \node at (0, -1.5) {$C_1$};
      % Curves
      \draw [->,color=myblue] (1.1, 0.8) to[out=-135,in=90] node[below right] {\blcircflsm{6}{rqud}} (0.4, -0.1);
      \draw [->,color=myred] (0.4, -1.1) to[out=-90,in=90] node[right] {\rdcircflsm{7}{rsdd}} (0.4, -1.7);
    \end{tikzpicture}\medskip
    \caption{Reduction by different message types}
    \label{fig-ex-sz-comm-1}
  \end{subfigure}
  \begin{subfigure}[b]{0.48\textwidth}
    \begin{tikzpicture}
      % Alignment
      \node at (-3.5, 0) {};
      \node [anchor=north west,text width=0.9cm,inner sep=4pt,draw] at (-2.5, -0.3) {{\small silent}};
      \node [anchor=north west,text width=2.3cm,inner sep=4pt,draw] at (1.2, 0.4) {{\small \blmsgsm{rqM} and \rdmsgsm{rsI} use different channels.}};

      \node at (0, 0.5) {$P$};
      \node at (-0.2, 0.15) {\tiny $6$};
      \node at (0, 0.15) {\tiny $7$};
      \node at (0.2, 0.15) {\tiny $8$};
      \draw [line width=0.2mm, <-<] (-0.2, 0) -- (-0.2, -1.2);
      \draw [line width=0.2mm, <-<] (0, 0) -- (0, -1.2);
      \draw [line width=0.2mm, >->] (0.2, 0) -- (0.2, -1.2);
      \node[label={[label distance=-4pt,myblue]left:{\small {\sf rqM}}},color=myblue] at (-0.2, -0.4) {$\bullet$};
      \node[label={[label distance=-2pt,myred]left:{\small {\sf rsI}}},color=myred] at (0, -0.8) {$\bullet$};
      \node[label={[label distance=-4pt,myred]right:{\small {\sf rqI}}},color=myred] at (0.2, -0.8) {$\bullet$};
      \node at (0, -1.5) {$C_2$};
      % Curves
      \draw [->,color=myblue] (-0.7, -1.9) to[out=110,in=-90] node[left] {\blcircflsm{2}{rquu}} (-0.9, -0.7);
      \draw [->,color=myred] (0.6, -1.1) to[out=-90,in=-90,distance=1.4cm] node[right=5pt] {\rdcircflsm{4}{immu}} (-0.6, -1.1);
    \end{tikzpicture}
    \caption{Reduction by the rule-template properties}
    \label{fig-ex-sz-comm-2}
  \end{subfigure}
  \caption{Nontrivial reduction cases}
  \label{fig-ex-sz-comm}
\end{figure}

In the first merge case, $[\blcircf{6}]$ can be pushed to the right, \ie{} $(\commstep{\blcircf{6}}{\rdcircf{7}})$ holds.
The object state transitions are straightforward to deal with, since they are orthogonal ($P$ for $\blcircf{6}$ and $C_1$ for $\rdcircf{7}$).
It is nontrivial to deal with the used channels, however, since the output of $\blcircf{6}$ (\blmsgsm{rqI}) and the input of $\rdcircf{7}$ (\rdmsgsm{rsM}) share the same channel $5$.
\autoref{fig-ex-sz-comm-1} depicts this case; we see $\blcircf{6}$ and $\rdcircf{7}$ still commute, since \rdcircfl{7}{rsdd} should take a ``response'' (\rdmsgsm{rsM}) while \blcircfl{6}{rqud} outputs a ``request'' (\blmsgsm{rqI}).
It indicates that $\blcircf{6}$ and $\rdcircf{7}$ are involved with different messages in the same channel, thus not affecting commutativity.
After the merge, we obtain a new (less-interleaved) history, shown in the middle of \autoref{fig-ex-sz-state-trs}.

Now we should merge $[\rdcircf{1}]$ and $[\rdcircf{3}; \rdcircf{4}; \rdcircf{5}; \rdcircf{7}]$; in this case, $\blcircf{2}$ can be pushed to the right.
While this reduction is trivial in the sense of orthogonal objects and channels, the only nontrivial case is between $\blcircf{2}$ and $\rdcircf{4}$, where both rules are executed in $C_2$.
These state transitions still commute, as shown in \autoref{fig-ex-sz-comm-2}, since $\blcircf{2}$ cannot make any object state transition, according to the definition of the ``rquu'' rule template.
After this merge we finally obtain the sequential history.

How can we argue that the atomic-history fragments are always mergeable?
As we start to see in the two cases in \autoref{fig-ex-sz-state-trs}, mergeability \emph{follows from the rule templates}.
While trying to merge two fragments, we especially look at the rule template used in the last state transition of the first fragment and figure out which state transitions can be performed between the two.
For example, when checking mergeability between $[\rdcircf{3}; \rdcircf{4}; \rdcircf{5}]$ and $[\rdcircf{7}]$, we find that $\rdcircf{5}$ generates the output message \rdmsgsm{rsM}, and it blocks all the other transactions to go from $P$ to $C_1$, \eg{} $\blcircf{6}$ was blocked until $\rdcircf{7}$ consumes \rdmsgsm{rsM}.
We can thus commute $\blcircf{6}$ and $\rdcircf{7}$ due to this blocking.
In this sense, in proving serializability, we look at each rule template and characterize the allowed state transitions between two atomic-history fragments.

\section{The Formal Proof of Serializability}
\label{sec-sz-proof}

Based on the intuitions from \autoref{sec-sz-pf-intuition}, in this section we provide the formal proof of serializability.
The biggest contribution of the \hemiola{} framework includes precise formalization of the intuitions -- merging atomic fragments, commutativity among rule templates, left/right pushes, etc. -- and the serializability proof employing those intuitions.
The highest-level theorem will simply claim that use of good topology and the rule templates automatically guarantees serializability.

We will use the example of interleaving transactions shown in \autoref{fig-ex-sz-trs} throughout the proof for better understanding of the entire proof, referred to as the ``interleaving example.''

\subsection{Semi-sequential histories}
\label{sec-semi-seq-hst}

In \autoref{sec-sz-pf-intuition} we briefly provided the intuition of making a history sequential by merging atomic-history fragments repeatedly.
In order to employ the intuition in the actual proof, we need to show that \emph{finitely many} reductions suffice.
For example, while merging two atomic-history fragments, if we happen to separate the other fragment between the two, we will never be sure whether the merging process will be finished with the sequential history or not.

\begin{figure}[t]
  \centering
  \begin{tabular}{|c|}
    \hline
    \begin{math}
      \begin{array}{cc}
        \inference[STSilent:]{}{\strsn{S}{\listsingle{\lblEmpty{}}}} &
        \inference[STIns:]{}{\strsn{S}{\listsingle{\lblIns{\listof{m}}}}} \\[20pt]
        \inference[STOuts:]{}{\strsn{S}{\listsingle{\lblOuts{\listof{m}}}}} &
        \inference[STAtomic:]{\atomic{\listof{\amsgi{m}}}{\listof{l}}{\listof{\amsge{m}}}}{\strsn{S}{\listof{l}}} \\[20pt]
      \end{array}
    \end{math}\\
    \hline
  \end{tabular}
  \caption{Semi-transactions}
  \label{fig-semi-trs}
\end{figure}

What would be the way to say \emph{how much} a given history is sequentialized?
Semi-transactions are defined in order to have a quantitative progress measure for reductions.
The definition, given in \autoref{fig-semi-trs}, is almost the same as for (ordinary) transactions, except that an atomic history does not need to be external.
Thanks to this relaxation, any atomic-history fragment is a semi-transaction.

Semi-sequential histories are also defined in a similar way:
\begin{definition}[Semi-Sequential Histories]
  A history $h$ is \emph{semi-sequential} with \emph{degree} $n$ iff the history is a concatenation of $n$ semi-transactions.
  \begin{displaymath}
    \hsseq{S}{h}{n} \triangleq \exists\, \listof{t}.\; \sizeof{\listof{t}} = n \wedge (\forall t \in \listof{t}.\; \strsn{S}{t}) \wedge h = \listconcat{\listof{t}}.
  \end{displaymath}
\end{definition}
The only difference from sequential histories is that we \emph{count} the number of semi-transactions.
In our interleaving example, looking at the original interleaved history shown in \autoref{fig-ex-sz-state-trs}, we can find the following semi-transactions in-order: $[\rdcircf{1}]$, $[\blcircf{2}]$, $[\rdcircf{3}; \rdcircf{4}; \rdcircf{5}]$, $[\blcircf{6}]$, $[\rdcircf{7}]$, and $[\blcircf{8}; \blcircf{9}; \blcircf{10}]$.
In this case, the degree of a semi-sequential history is $6$, the number of semi-transactions.
Note that the degree of a semi-sequential history is not uniquely determined.
In the example, when regarding $[\rdcircf{3}; \rdcircf{4}; \rdcircf{5}]$ to the three separate single-label atomic histories -- $[\rdcircf{3}]$, $[\rdcircf{4}]$, and $[\rdcircf{5}]$ -- then we obtain another semi-sequential history with degree $8$.

This definition indicates that in order to obtain a serialized history, we should perform reductions to \emph{decrease the count as much as possible}.
\hemiola{} employs theorems that reflects this intuition:
\begin{theorem}
  \label{thm-sseq-default}
  Given a system $S$, a legal history is always semi-sequential:
  \begin{displaymath}
    \forall h.\; \semleg{S}{h} \to \exists n.\; \hsseq{S}{h}{n}.
  \end{displaymath}
\end{theorem}
\begin{proof}
  The proof is straightforward, since by definition any single-label history is a semi-transaction, and thus any history is semi-sequential, \ie{} $\forall h.\; \hsseq{S}{h}{\sizeof{h}}$.
\end{proof}

\begin{theorem}[Semi-sequentiality and serializability]
  \label{thm-sseq-sz}
  If $S$ satisfies the following property, then $S$ is serializable:
  \begin{align*}
    \forall h, n, s.\; & \semsteps{S}{\sysInit{S}}{h}{s} \land \hsseq{S}{h}{n} \to \\
    & \hseq{S}{h}\; \vee\\
    & \exists h_r, m.\; \semsteps{S}{\sysInit{S}}{h_r}{s} \wedge \hsseq{S}{h_r}{m} \wedge m < n.
  \end{align*}
\end{theorem}
\begin{proof}
  The proof employs the well-foundness of the less-than operator ($<$) for natural numbers.
  For a given history $h$ in a system $S$, we can find an initial number $n$ that satisfies $\hsseq{S}{h}{n}$ (by \autoref{thm-sseq-default}).
  Now by the given property, $h$ is either already sequential or reduces to $h_r$ with the degree $m < n$.
  Therefore, finite iteration of the property will eventually reduce the history to a sequential history.
\end{proof}

\subsection{Reduction of external input/output labels}
\label{sec-red-ext-labels}

For a given legal history in a system, the very first step to reduce it to a sequential history is to push all external input and output labels to the leftmost and rightmost regions of the history, respectively.
Recall that the serializability (\autoref{def-seq-sz}) does not require the sequential history to preserve the behavior of a history, but to reach to the same state.

The following two dual theorems are enough to push all external labels:
\begin{theorem}
  \label{thm-push-ext-labels}
  In any legal history in the system $S$, the first external-input (or the last external-output) label can be pushed to the first (or the last) of the history, respectively:
  \begin{displaymath}
    \forall s_0, s_1, \listof{h_0}, im, \listof{h_1}.\;
    \mathsf{NoExtIns}(\listof{h_0}) \to
    \semsteps{S}{s_0}{\listapp{\listcons{\listof{h_0}}{\lblIns{im}}}{\listof{h_1}}}{s_1} \to
    \semsteps{S}{s_0}{\listapp{\lblIns{im}}{\listapp{\listof{h_0}}{\listof{h_1}}}}{s_1}\ \textrm{and}
  \end{displaymath}
  \begin{displaymath}
    \forall s_0, s_1, \listof{h_0}, im, \listof{h_1}.\;
    \mathsf{NoExtOuts}(\listof{h_1}) \to
    \semsteps{S}{s_0}{\listapp{\listcons{\listof{h_0}}{\lblOuts{im}}}{\listof{h_1}}}{s_1} \to
    \semsteps{S}{s_0}{\listapp{\listapp{\listof{h_0}}{\listof{h_1}}}{\lblOuts{im}}}{s_1},
  \end{displaymath}
  where $\mathsf{NoExtIns}(\listof{h}) \triangleq \forall l.\; l \in \listof{h} \to \forall im.\; l \neq \lblIns{im}$ and
  $\mathsf{NoExtOuts}(\listof{h}) \triangleq \forall l.\; l \in \listof{h} \to \forall im.\; l \neq \lblOuts{im}$.
\end{theorem}
\begin{proof}
  By definition it suffices to prove \commhst{\listof{h_0}}{\listsingle{\lblIns{im}}}.
  Since $\mathsf{NoExtIns}(\listof{h_0})$, each label in $\listof{h_0}$ is a silent, external-output, or internal label.
  It is trivial that a silent label and an external-input label commute, since the silent label makes no state transition.
  An external-output label and an external-input label also commute, since they use different channels.
  Commutativity between an internal label and an external-input label is relatively nontrivial, since an internal label may dequeue some external inputs.
  They still commute, however, since dequeue of an external-input label means there is already an external input message in the channel, and the external-input label adds a different message to the system.
  The proof for the external-output label is almost same as the one for the external-input label.
\end{proof}

\tikzset{
  ->-/.style={
    decoration={
      markings,
      mark=at position #1 with {\arrow{>}}},
    postaction={decorate}
  }
}
\begin{figure}[h]
  \centering
  \begin{tikzpicture}
    \draw[->-=0.5] (-0.8, 0) -- (-0.4, 0);
    \draw[fill=myred, text=white] (0,0) circle [radius=0.4] node {$l^0_{\textrm{in}}$};
    \draw[->-=0.5] (0.4, 0) -- (0.8, 0);
    \draw[fill=mygray, text=white] (1.2,0) circle [radius=0.4] node {$l^0_{\textrm{int}}$};
    \draw[->-=0.5] (1.6, 0) -- (2.0, 0);
    \draw[fill=myblue, text=white] (2.4,0) circle [radius=0.4] node {$l^0_{\textrm{out}}$};
    \draw[->-=0.5] (2.8, 0) -- (3.2, 0);
    \draw[fill=myred, text=white] (3.6,0) circle [radius=0.4] node {$l^1_{\textrm{in}}$};
    \draw[->-=0.5] (4.0, 0) -- (4.4, 0);
    \draw[fill=mygray, text=white] (4.8,0) circle [radius=0.4] node {$l^1_{\textrm{int}}$};
    \draw[->-=0.5] (5.2, 0) -- (5.6, 0);
    \draw[fill=myblue, text=white] (6,0) circle [radius=0.4] node {$l^1_{\textrm{out}}$};
    \draw[->-=0.5] (6.4, 0) -- (6.8, 0);

    \node at (3.0, -1.0) {\small $\downarrow^{\ast}$ (after some reductions)};

    \draw[->-=0.5] (-0.8, -2.0) -- (-0.4, -2.0);
    \draw[fill=myred, text=white] (0,-2.0) circle [radius=0.4] node {$l^0_{\textrm{in}}$};
    \draw[->-=0.5] (0.4, -2.0) -- (0.8, -2.0);
    \draw[fill=myred, text=white] (1.2,-2.0) circle [radius=0.4] node {$l^1_{\textrm{in}}$};
    \draw[->-=0.5] (1.6, -2.0) -- (2.0, -2.0);
    \draw[fill=mygray, text=white] (2.4,-2.0) circle [radius=0.4] node {$l^0_{\textrm{int}}$};
    \draw[->-=0.5] (2.8, -2.0) -- (3.2, -2.0);
    \draw[fill=mygray, text=white] (3.6,-2.0) circle [radius=0.4] node {$l^1_{\textrm{int}}$};
    \draw[->-=0.5] (4.0, -2.0) -- (4.4, -2.0);
    \draw[fill=myblue, text=white] (4.8,-2.0) circle [radius=0.4] node {$l^0_{\textrm{out}}$};
    \draw[->-=0.5] (5.2, -2.0) -- (5.6, -2.0);
    \draw[fill=myblue, text=white] (6,-2.0) circle [radius=0.4] node {$l^1_{\textrm{out}}$};
    \draw[->-=0.5] (6.4, -2.0) -- (6.8, -2.0);
  \end{tikzpicture}
  \caption{Pushing all external input/output labels}
  \label{fig-reducing-exts}
\end{figure}

\autoref{fig-reducing-exts} shows an original example history and the resulting history after pushing all the external input and output labels in the original history.
We can generate such a history by performing reductions:
\begin{itemize}
\item Try to pick the first external-input label that is \emph{not in the leftmost region of the history yet}. If it exists, it can always be pushed to the left, right after the external-input labels that are already in the leftmost region, by applying \autoref{thm-push-ext-labels}.
\item Try to pick the last external output label that is \emph{not at the rightmost region of the history yet}. If it exists, it can always be pushed to the right, right before the external-output labels that are already in the rightmost region, by applying \autoref{thm-push-ext-labels}.
\end{itemize}
Note that pushing the external input (output) labels to the leftmost (rightmost), respectively, is possible since the semantics of the protocol transition system is based on infinite-sized buffers, allowing the system to accept all the external input messages as early as possible and to postpone releasing all the external output messages as late as possible.

\subsection{Interleaving and nonconfluent histories}
\label{sec-itlv-ncf-hst}

Now we formalize the atomic-history fragments mentioned in \autoref{sec-sz-pf-intuition} -- whether the two fragments belong to the same transaction or not.
From this section, we will just deal with histories only consisting of internal labels, to focus on how to serialize atomic histories, assuming external labels are already pushed to the edges by the method described in \autoref{sec-red-ext-labels}.

The below notion of continuity lets us figure out whether two histories are related as adjacent parts of a whole atomic history:
\begin{definition}[Continuity]\mbox{}\vspace{-8pt}\\
  \begin{enumerate}
  \item Two atomic histories $h_1$ and $h_2$ are continuous (\hcontsymb{}) iff the initial messages of $h_2$ are in the live messages of $h_1$:
    \begin{displaymath}
      \hcont{h_1}{h_2}\; \triangleq\quad \atomic{\listof{\amsgi{im_1}}}{h_1}{\listof{\amsge{im_1}}} \;\wedge\; \atomic{\listof{\amsgi{im_2}}}{h_2}{\listof{\amsge{im_2}}} \;\wedge\; \listof{\amsgi{im_2}} \subseteq \listof{\amsge{im_1}}.
    \end{displaymath}
  \item We say $h_1$ and $h_2$ are externally continuous (denoted as $\hextcont{S}{h_1}{h_2}$) if they are continuous and $h_1$ is externally atomic.
  \item Two atomic histories $h_1$ and $h_2$ are discontinuous iff the live messages of $h_1$ are disjoint from the initial messages of $h_2$:
    \begin{displaymath}
      \hdiscont{h_1}{h_2}\; \triangleq\quad \atomic{\listof{\amsgi{im_1}}}{h_1}{\listof{\amsge{im_1}}} \;\wedge\; \atomic{\listof{\amsgi{im_2}}}{h_2}{\listof{\amsge{im_2}}} \;\wedge\; \listdisj{\listof{\amsge{im_1}}}{\listof{\amsgi{im_2}}}.
    \end{displaymath}
  \end{enumerate}
\end{definition}
Note that the discontinuity requires that the live messages of the previous history are \emph{disjoint} to the initial messages of the next history.
Therefore, it is not true that two atomic histories are always either continuous or discontinuous.
We will very soon explore how to deal with the other case, where the next history takes multiple sets of live messages from the previous histories.

Using the notion of continuity, we can also formalize interleaving of atomic histories:
\begin{definition}[Interleaved Histories]
  In a given system $S$, a sequence of histories $\listof{h}$ is interleaved iff there exist two histories $h_1$ and $h_2$ in the sequence that are externally continuous and any history between the two is discontinuous to $h_1$:
  \begin{align*}
    \hitlv{S}{\listof{h}}\; \triangleq\quad & \exists h_1, h_2, \listof{h_1}, \listof{h_2}, \listof{h_3}. \\
    & \listof{h} = \listapp{\listcons{\listapp{\listcons{\listof{h_1}}{h_1}}{\listof{h_2}}}{h_2}}{\listof{h_3}}\; \wedge \\
    & \hextcont{S}{h_1}{h_2} \wedge (\forall h' \in \listof{h_2}.\; \hdiscont{h_1}{h'}).
  \end{align*}
  We also call a history $h$ interleaved, overrided as \hitlv{S}{h}, iff we can find an interleaved sequence of histories $\listof{h_s}$ that satisfies $h = \listconcat{\listof{h_s}}$.
\end{definition}

There are two subtleties in defining the notion of interleaving precisely.
First, we look for \emph{externally continuous} histories, not just continuous ones, to define whether the whole history is interleaved or not.
It does not restrict the notion since when continuous histories are found in a legal history, either they are already externally continuous or the ones are found at the beginning of the atomic-history chain that contains them.
Second, we require that the earlier history ($h_1$) is \emph{discontinuous} to each history ($\forall h' \in \listof{h_2}$) between the two externally continuous histories ($h_1$ and $h_2$).
This is to ensure that the live messages generated by $h_1$ are preserved -- \ie{} not consumed by some other atomic histories -- until $h_2$ takes its initial messages from those ones.

One of the main intuitions to prove serializability is to categorize a given history.
If the history is already sequential, we do not need to proceed further.
If the history is interleaved, we will need to merge the externally continuous histories, which will decrease the degree of semi-sequentiality and lead to a sequential history.
This categorization, however, implicitly assumes any history is either sequential or interleaved.

\begin{figure}
  \centering
  \begin{tabular}{cc}
    \begin{tabular}{c}
      \begin{tikzpicture}
        \node[anchor=east] at (-1.4, 0.25) {$h_1$};
        \node[anchor=east] at (0.0, 0) {$\squigs{5}\rsquigend\ \listof{\amsge{im_1}}$};
        \node at (0.3, 0) {$\supseteq$};
        \node[anchor=west] at (2.0, 0.25) {$h_2$};
        \node[anchor=west] at (0.6, 0) {$\listof{\amsgi{im_2}}\ \squigs{5}\rsquigend$};
        \node at (0.3, -1.0) {{\small{\bf (a)} Continuous}};
      \end{tikzpicture} \\
      \begin{tikzpicture}
        \node[anchor=east] at (-1.4, 0.25) {$h_1$};
        \node[anchor=east] at (0.0, 0) {$\squigs{5}\rsquigend\ \listof{\amsge{im_1}}$};
        \node at (0.3, 0) {$\#$};
        \node[anchor=west] at (2.0, 0.25) {$h_2$};
        \node[anchor=west] at (0.6, 0) {$\listof{\amsgi{im_2}}\ \squigs{5}\rsquigend$};
        \node at (0.3, -1.0) {{\small{\bf (b)} Discontinuous}};
      \end{tikzpicture}
    \end{tabular} &
    \adjustbox{valign=c}{
      \begin{tikzpicture}
        \node[anchor=east] at (-1.4, 1.05) {$h_0$};
        \node[anchor=east] at (0.0, 0.8) {$\squigs{5}\rsquigend\ \listof{\amsge{im_0}}$};
        \node at (-0.5, 0) {$\vdots$};
        \node[anchor=east] at (-1.2, -0.5) {$h_{(n-1)}$};
        \node[anchor=east] at (0.0, -0.8) {$\squigs{5}\rsquigend\ \listof{\amsge{im_n}}$};

        \node[anchor=west] at (2.4, 0.25) {$h_n$};
        \node[anchor=west] at (1.0, 0) {$\listof{\amsgi{im_n}}\ \squigs{5}\rsquigend$};

        \draw [->, >=stealth, line width=0.6pt] (0.0, 0.8) -- (0.9, 0.2);
        \node at (0.2, 0) {$\vdots$};
        \draw [->, >=stealth, line width=0.6pt] (0.0, -0.8) -- (0.9, -0.2);

        \node at (0.3, -2.0) {{\small{\bf (c)} Confluent}};
      \end{tikzpicture}}\\
  \end{tabular}
  \caption{Three relation types between atomic histories}
  \label{fig-atomic-hst-three-types}
\end{figure}

An additional condition is required, unfortunately, just to reason with sequential and interleaved histories.
In other words, there is a third type of a history, happening when at least two different external atomic histories come together via a local state transition consuming some live messages of these histories.
\autoref{fig-atomic-hst-three-types} depicts the three types of relations between two atomic histories.
While atomic-history fragments in an interleaved history are only expected to be continuous or discontinuous to each other, there is another relation type, which is called \emph{confluent} histories.
This confluence case does not happen in any practical cache-coherence protocols, but we still need a formal predicate to ensure that the target system never generates such cases.

The \emph{nonconfluence} predicate removes this case, by claiming that any atomic history is either the start of a new transaction or a continuation of a previous transaction:
\newcommand{\sncf}[1]{\ensuremath{\mathsf{Nonconfluent}\ #1}}
\begin{definition}[Nonconfluence]
  A system $S$ is \emph{nonconfluent} iff any first non-external history (if it exists) is interleaved (with an external atomic history):
  \begin{displaymath}
    \begin{array}{rcl}
      \sncf{S}\; \triangleq\quad & \forall \listof{h}, h_0, s. & \semsteps{S}{\sysInit{S}}{\listapp{\listconcat{\listof{h}}}{h_0}}{s}
      \wedge\; (\forall h \in \listof{h}.\; \extatomicShort{S}{h})
      \wedge\; \neg(\extatomicShort{S}{h_0}) \to\\
      & & \hitlv{S}{(\listcons{\listof{h}}{h_0})}.
    \end{array}
  \end{displaymath}
\end{definition}

\subsection{Reduction of atomic-history fragments}

\subsection{Serializability guarantee by \hemiola{}}

\chapter{Related Work I: Approaches to Dealing with Interleavings}
\label{sec-related-work-i}
